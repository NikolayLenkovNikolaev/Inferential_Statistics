{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKkvGLYH+l2w5WsAClTuDR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikolayLenkovNikolaev/Inferential_Statistics/blob/main/10_Asymptotic_Evaluations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.1. Point Estimation\n",
        "\n",
        "\n",
        "### 10.1.1. COnsistency\n",
        "\n",
        "10.1.1. A sequence of estimators W_n = W_n(X_1,.. X_n)$$ is a consistent sequence of estimators of the parameter $\\theta$ if, for every $\\epsilon > 0$\n",
        " and every $\\theta \\in \\Theta$\n",
        " $$lim_{n-> \\infty} P_{\\theta} (|W_n - \\theta| < \\epsilon)= 1$$\n",
        "\n",
        " ex: 10.1.2. Consistency of $\\bar{X}$\n",
        "\n",
        " Theorem: 10.1.3. If $W_n$ is a sequence of estimators of a parameter $\\theta$ msatisfyinf\n",
        " i. $lim_{n->\\infty} Var_{\\theta}[W_n] = 0$\n",
        "ii. $lim_{n->\\infty} Bias_{\\theta}[W_n] = 0$\n",
        "\n",
        "for every $\\theta \\in \\Theta$ os a cpmsostemt sequence of estimators of $\\theta$\n",
        "\n",
        "ex: 10.1.4.\n",
        "\n",
        "Theorem: 10.1.5. Let $W_n$ be a consistent sequence of estimators of a parameter $\\theta$. Let $a_1, 1_2...$ and $b_1, b_2...$ be seqeunces of constants satisfying:\n",
        "i. $lim_{n-> \\infty} a_n = 1$\n",
        "ii. $lim_{n-> \\infty} b_n = 0$\n",
        "Then the sequence $U_n = a_n.W_n + b_n$ is a consistent sequence of estimatros of $\\theta$\n",
        "\n",
        "Theorem: 10.1.6. Consistency of MLWs: let $X_1,X_2...$ be iid $f(x|\\theta)$ and let $L(\\theta|x)= \\prod_{i=1^n} f(x_i|\\theta)$ be the likelihood function. Let $\\hat{\\theta}$ denote the MLE of $\\theta$. Let $\\tau(\\theta)$ be acontinuous function of $\\theta$. Under the regulatory conditions in Miscellanea 10.6.2 on $f(x|\\theta)$ and , hebce, $L(\\theta|x)$ for every $\\epsilon > 0$ and every $\\theta \\in \\Theta$\n",
        "\n",
        "$$lim_{n-\\infty} P_{\\theta}(|\\tau(\\hat{\\theta}) - \\tau(\\theta)| >= ϵ) = 0$$\n",
        "\n",
        "Then is $\\tau(\\hat{\\theta})$ ios a consistent estimator of $\\tau(\\theta)$\n",
        "\n",
        "Proof:\n",
        "\n",
        "### 10.1.2. Efficiency\n",
        "\n",
        "For an estimatro $T_n$ if $lim_{n->\\infty} k_n Var[T_n] = \\tau^2 < \\infty$ where $\\{k_n \\}$ is a sequence of constants, then $\\tau^2$ is called the limiting variance or limit of the variances\n",
        "\n",
        "ex: 10.1.8: limiting variances\n",
        "\n",
        "10.1.9. For an estimator $T_n$, suppose that $k_n (T_n - \\tau(\\theta)) -> N(0, \\sigma^2)$ in distribution . The parameter $\\sigma^2$ is called the asymptotic variance or variance of the limit distribution of $T_n$\n",
        "\n",
        "ex: 10.1.10 Large sample mixture varinces\n",
        "\n",
        "10.1.11. A sequence of estimators W_n is asymptotically efficient for a parameter $\\tau(\\theta)$ if $\\sqrt{n}|W_n - \\tau(\\theta)| -> N(0, ν(\\theta))$ in distribution and\n",
        "$$\\nu(\\theta) = \\frac{[\\tau`(\\theta)]^2}{E_{\\theta(.......)}}$$\n",
        "\n",
        "That is , the asymptotic variance of $W_n$ achieves the Cramer-Rao Lowe Bound\n",
        "\n",
        "Theorem: 10.1.12. Asymptotic aefficiency of MLEs: Let $X_1,X_2 ...$ be iid $f(x|\\theta)$ let $\\hat{\\theta}$ denote the MLE of $\\theta$, and let $\\tau(\\theta)$ be a continuous function of $\\theta$. Under the regularity conditions in miscellanea 10.6.2. of $f(x|\\theta)$ and hence $L(\\theta|x)$\n",
        "$$\\sqrt{n} [\\tau(\\hat{\\theta})) - \\tau(\\theta)] -> N(0, \\nu(\\theta))$$\n",
        "\n",
        "where $\\nu(\\theta)$ is the Cramer Rao Lower Bound. That is $\\tau(\\hat{\\theta})$ is a consistent and asymptotically efficinet estimator of $\\tau(\\theta)$\n",
        "\n",
        "Proof:\n",
        "\n",
        "ex: 10.1.13 Asymptotic normality and consitency\n",
        "\n",
        "### 10.1.3. Calculations and COmparisons:\n",
        "\n",
        "ex: 10.1.14 Approximate binomial variance\n",
        "\n",
        "ex: 10.1.15:\n",
        "\n",
        "10.1.16: if two estimators $W_n$ and $V_n$ satisfy:\n",
        "- $\\sqrt{n}[W_n = \\tau(\\theta)] -> N(0, \\sigma_W^2)$\n",
        "- $\\sqrt{n}[V_n = \\tau(\\theta)] -> N(0, \\sigma_V^2)$\n",
        "in distribution, the asymptotic relative efficiency ARE of $V_n$ with respect to $W_n$ is $ARE(V_n, W_n) = \\frac{\\sigma_W^2}{\\sigma_V^2}$\n",
        "\n",
        "ex: 10.1.17: AREs of Poisson estimators\n",
        "\n",
        "ex: 10.1.18: estimating a gamma mean\n",
        "\n",
        "### 10.1.4. Bootstrap Standard Errors\n",
        "\n",
        "ex: 10.1.10 Boostrap a variance:\n",
        "\n",
        "ex: 10.1.20. Bootstrapping a binomial variance\n",
        "\n",
        "ex. 10.1.21 Conclusion od ex\n",
        "\n",
        "ex: 10.1.22. Parametric bootstrap\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oe1-aKChQCqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RARMjnpbQCuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.2. Robustness\n",
        "\n",
        "### 10.2.1. The Mean and the Median\n",
        "\n",
        "ex: 10.2.1. Robustness of the sample mean\n",
        "\n",
        "10.2.2. Let $X_{(1)} < .. < X_{(n)}$ be an ordered sample of size n and let $T_n$ be a statistic based on this sample $T_n$ has breakdown value b, $0 =< b=< 1$ if for every $\\epsilon >0$\n",
        "\n",
        "$$lim_{(1-b)n-> \\infty} T_n < \\infty$$ and\n",
        "$$lim_{(1-(b+ \\epsilon)n)-> \\infty} T_n = \\infty$$\n",
        "\n",
        "ex: 10.2.3. Asymptotic normality of the median\n",
        "\n",
        "ex: 10.2.4. AREs of the median tothe mean\n",
        "\n",
        "### 10.2.2. M-estimators\n",
        "\n",
        "ex: 10.2.5. Huber estimator\n",
        "\n",
        "ex: 10.2.6. Limit distribution of the Huber estimator\n",
        "\n",
        "ex: 10.2.7 ARE of the Huber estimator\n",
        "\n"
      ],
      "metadata": {
        "id": "nXhtKaUKQCws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MeQnAbIjQCzQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 10.3. Hypothesis testing\n",
        "\n",
        "\n",
        "### 10.3.1. Asymptotic DIstribution of LRTs\n",
        "\n",
        "Theorem: 10.3.1. Asymptotic distribution of the LRT-simple $H_0$\n",
        "\n",
        "For tesing $H_0: \\theta=\\theta_0$ versus $H_1: \\theta \\ne \\theta_0$, suppose $X_1...X_n$ are iid $f(x|\\theta), \\hat{\\theta}$ is te MLE of $\\theta$ and $f(x|\\theta)$ satisfies the regularity conditions in Miscellanea 10.6.2. . Then under $H_0$ as $n-> \\infty$\n",
        "\n",
        "$$-2.log{\\lambda(X)} - \\chi_1^2$$ in distribution\n",
        "\n",
        "where $\\chi_1^2$ is a $\\chi_2$ random variable with 1 degree of freedom.\n",
        "\n",
        "Proof:\n",
        "\n",
        "Ex: 10.3.2. Poisson LRT\n",
        "\n",
        "Theorem: 10.3.3. Let $X_1..X_n$ be a random sample from a pdf or pmf $f(x|\\theta)$. Under the regularity conditions in Miscellanea 10.6.2. if $\\theta \\in \\Theta_0$, then the distribution of the statistic $-2/log{\\lambda(X)}$ converges to a ci squared distribution as the sample size $n-> \\infty$. The degrees of freedom of the limiting distribution is the difference between the number of free parameters specified by $\\theta \\in \\Theta_0$ and the number of free parameters specified by $\\theta \\in \\Theta$\n",
        "\n",
        "ex: 10.3.4. Multinomial LRT\n",
        "\n",
        "### 10.3.2. Other Large-Sample Tests\n",
        "\n",
        "ex: 103.5. Large sample binomial tests\n",
        "\n",
        "ex: 10.3.6. Binomial score test\n",
        "\n",
        "ex: 10.3.7. Tests based on the Huber estimator\n",
        "\n"
      ],
      "metadata": {
        "id": "BtAVhIInQC1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "H_1"
      ],
      "metadata": {
        "id": "pVFErqSOQC3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.4. Interval Estimation\n",
        "\n",
        "### 10.4.1. Approximate Maximum Likelihood Intervals\n",
        "\n",
        "ex: continuatuin\n",
        "\n",
        "ex: 10.4.2. Binomial score interval\n",
        "\n",
        "ex: 104.3. Binomial LRT interval\n",
        "\n",
        "### 10.4.2. Other Large Sample intervals\n",
        "\n",
        "ex: 10.4.4. Approximate interval\n",
        "\n",
        "ex: 10.4.5. Approximate Poisson interval\n",
        "\n",
        "ex: 10.4.6. More on the binomial score interval\n",
        "\n",
        "ex: 10.4.7. Comparison of binomial intervals\n",
        "\n",
        "ex: 10.4.8. Intervals based on the Huber estimator\n",
        "\n",
        "ex: 10.4.9. NMegative binomial interval\n",
        "\n"
      ],
      "metadata": {
        "id": "mDcQEWm5QC6A"
      }
    }
  ]
}