{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKBjrYNxq7DLkZ2wq2HxJJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikolayLenkovNikolaev/Inferential_Statistics/blob/main/7_Point_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 Introduction\n",
        "\n",
        "7.1.1. A point estimator is any function $W(X_1..X_nj)$ of a sample; that is , any statistic is apoint estimator.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h2CuMJ_0PGKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2. Methods of Finding Estimators\n",
        "\n",
        "### 7.2.1, Nethiod of Moments:\n",
        "\n",
        "7.2.1. Normal method of moments\n",
        "\n",
        "7.2.2. Binomial method of moments\n",
        "\n",
        "7.2.3. Satterthwaite approximation\n",
        "\n",
        "### 7.2.2. Maximum Likelihood Estimator:\n",
        "\n",
        "Likelihood function:\n",
        "\n",
        "$$L(\\theta|x) = L(\\theta_1...\\theta_k| x_1...x_n) = \\prod_{i=1}^n f(x_i|\\theta_1,... \\theta_k)$$\n",
        "\n",
        "7.2.4. For each sample poin x, let $\\hat{\\theta}(x)$ be a parameter value at which $L(\\theta|x)$ attains its maximum as a function of $\\theta$, with x held fixed. A miximum likelihood estimator MLE of the parameter $\\theta$ base on a sample X is $\\theta(X)$\n",
        "\n",
        "ex: 7.2.5/6 Normal Likeihood\n",
        "\n",
        "ex: 7.2.7. Bernoulli MLE\n",
        "\n",
        "ex: 7.2.8. Restricted range MLE\n",
        "\n",
        "ex: 7.2.9 Binomial MLE, unknown number of trails\n",
        "\n",
        "Theorem 7.2.10: Invariance of MLEs:\n",
        "\n",
        "If  $\\hat{\\theta}$ is the MLE of $\\theta$, then for any function $\\tau(\\theta)$. the MLE of $\\tau(\\theta)$ is $\\tau(\\hat{θ})$\n",
        "\n",
        "Proof:\n",
        "\n",
        "ex: 7.2.11. Normal MLEs, $\\mu $ and $\\sigma$ unknown\n",
        "\n",
        "ex: 7.2.12.\n",
        "\n",
        "ex: 7.2.13\n",
        "\n",
        "### Bayes Estimators:\n",
        "\n",
        "ex: 7.2.14. Binomial Bayes Estimation:\n",
        "\n",
        "7.2.15. Let $\\mathcal{F}$ denote the class of pdfs or pmfs $f(x|\\theta)$. A class $\\prod$ of prior distribution is conjugate family for $\\mathcal{F}$ if the postrior distribution is in the class $\\prod$ fir akk $f \\in \\mathcal{F}$ all priors in $\\prod$ and all $x \\in \\mathcal{X}$\n",
        "\n",
        "ex: 7.2.16. Normal Bayes estimators\n",
        "\n",
        "\n",
        "### 7.2.4. The EM algorithm:\n",
        "\n",
        "ex: 7.2.17 Multiple Poisson rates\n",
        "\n",
        "Theorem: 7.2.20 Monotonic EM sequence:\n",
        "The sequence {$\\hat{\\theta_{(r)}}$} defined by 7.2.20 satisfies:\n",
        "\n",
        "$$L(\\hat{\\theta}^{(r+1)}|y) >= L(\\hat{\\theta}^{(r)}|y)$$\n",
        "\n",
        "with equality holding if and only if successive iterations yield the same value of the maximized expected complete-data log likelihood , that is:\n",
        "\n",
        "$$E[log L(\\hat{\\theta}^{(r+1)}|y,X)| \\hat{\\theta}^{(r)}, y] = E[log L(\\hat{\\theta}^{(r)}|y,X)| \\hat{\\theta}^{(r)}, y]$$$\n"
      ],
      "metadata": {
        "id": "sQikuH0cPGPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vvox55pHPGRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.3. Methods of Evaluating Etimators\n",
        "\n",
        "### 7.3.1. Mean Squared Error\n",
        "\n",
        "7.3.1. The mean squared errors MSE of an estimator W of a parameter $\\theta$ is the function of $\\theta$ defined by $\\E_{\\theta}(W- \\theta)^2$\n",
        "\n",
        "7.3.2. The bias of apoint estimator W of a parameter $\\theta$ us the difference between the expected value of W and $\\theta$; that is , $BIAS_{\\theta} W - E_{\\theta}[W- \\teta]$. An estimator whose bias is identically in $\\theta$ equal to 0 is called unbiased and satisfies $E_{\\theta} W = \\theta$ for all $\\theta$.\n",
        "\n",
        "ex: 7.3.3 Normal MSE\n",
        "\n",
        "ex: 7.3.5. MSE of binomial Bayes estimator\n",
        "\n",
        "ex: 7.3.6. MSE of equivariant estimators\n",
        "\n",
        "### Best Unbiased Estimators\n",
        "\n",
        "7.3.7. An estimator W* is a best unbiased estimator of $\\tau(θ)$ if it satisfies $E_{\\theta}[W*] = \\tau(\\theta)$ for all $\\theta$ and , for any other estiator W with $E_{\\theta}[W]= \\tau(\\theta)$, we have $Var_{\\theta}[W*] =< Var_{\\theta}[W]$ for all $\\theta$. W* is also called a uniform minimum variance unbiased estimatro UMVUE of $\\tau(\\theta)$\n",
        "\n",
        "Poisson 7.3.8. Poisson unbiased estimation\n",
        "\n",
        "Theorem: 7.3.9. Cramer Ra0 Inequality:\n",
        "\n",
        "Let $X_1..X_n$ be a sample with pdf $f(x|\\theta)$ and let $W(X) = WX_1..X_n()$ be any estimator satisfying:\n",
        "\n",
        "$$\\frac{d}{d\\theta}E_{\\theta}[W(X)] = \\inf_{\\mathcal{x}} \\frac{......}{}$$\n",
        "\n",
        "and $$Var_{\\theta}[W(X)] < \\infty$$\n",
        "\n",
        "Then:\n",
        "\n",
        "$$Va_{\\theta}(W(X)) >= \\frac{}{}$$\n",
        "\n",
        "Proof:\n",
        "\n",
        "Corrolary 73.10 Crammer-Rao Inequality iid case\n",
        "\n",
        "Lemma 7.3.12.\n",
        "\n",
        "Ex: 7.3.13. Unbiased estimator for the scale uniform\n",
        "\n",
        "ex: 7.3.14 Normal variance bound\n",
        "\n",
        "Corollary 7.3.15: Attainment:\n",
        "\n",
        "### 7.3.3. Sufficiency and Unbiasedness\n",
        "\n",
        "Theorem:7.3.17 Rao-Blackwell.\n",
        "let W be ay unbiased estimator of $\\tau(\\theta)$ and let t be a sufficient statistic for $\\theta$. Define $ϕ (T) = E[W|T]$. Then $E_{\\theta}[\\phi(T)] = \\tau(\\theta)$ and $Var_{\\theta}[\\phi (T)] =< Var_{\\theta}[W]$ for all $\\theta$. That is $\\phi(T)$ is a uniformly better inbiased estimator of $\\tau(\\theta)$\n",
        "\n",
        "Proof:\n",
        "\n",
        "ex: 7.3.18. Conditioning on an insufficient statistic\n",
        "\n",
        "Theorem: 7.3.19: If W is a best unbiased estimator of $\\tau(\\theta)$ then W is unique\n",
        "\n",
        "Proof:\n",
        "\n",
        "Theorem: 7.3.20: If $E_{\\theta}[W]= \\tau(\\theta), W$ is the best unbiased estimator of $\\tau(\\theta)$ if and only if W is uncorrelated with all unbiased estimators of 0.\n",
        "\n",
        "Proof\n",
        "\n",
        "ex: 7.3.21. Unbiased estimators of zero\n",
        "\n",
        "Theorem: 7.3.23. Let T be a complete sufficent statistic ofr a parameter $\\theta$ and let $\\phi(T)$ be any estimator based only on T. Then $\\phi(T)$ is the unique unbiased estimator of its expected value.\n",
        "\n",
        "ex: 7.3.24. Binomial best unbiased estimation\n",
        "\n",
        "### 7.3.4. Loss Function optimality:\n",
        "\n",
        "ex: 7.3.25. Binomial risk functions\n",
        "\n",
        "ex: 7.3.26 Risk of normal variance\n",
        "\n",
        "ex: 7.3.27 : Variance estimation using Stein loss\n",
        "\n",
        "ex: 73.28 Towe Bayes rules\n",
        "\n",
        "ex: 7.3.29: Normal Bayes estimates\n",
        "\n",
        "ex: 7.3.30 Binomial Baye estimates\n",
        "\n"
      ],
      "metadata": {
        "id": "C_cnRdnSPGTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V8xqM9l5PGWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fWwhnnSePGYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b165Q1QrPGaF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3a8ddqu6PGcT"
      }
    }
  ]
}