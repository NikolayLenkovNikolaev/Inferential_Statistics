{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjBHfWMo9V2+beM+qMK4nh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikolayLenkovNikolaev/Inferential_Statistics/blob/main/10_1_Borroni_Asimptotic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xDddhISAhp_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "y6KLPD2ihqCn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teoria Asintotica degli stimatori\n",
        "\n",
        "COme abbiamo visto (Legge dei grandi numeri, Teorema centrale del limite) quando l'ampiezza campionaria tende all'infinito si possono ricavare importanti proprieta degli stimatori inferenziali: si parla di proprieta asintotiche.\n",
        "\n",
        "Per cli sitmatori , questa e' un occassione per disporre di un ulteriore criterio di scelta. In particolare, come vedreo, gli stimatori di massima verosimilianza godono di proprieta che alti stimatori non hanno.\n",
        "\n",
        "Nella pritica , non potremo mai dispore di campioni con ampiezza infinita. Tuttavia la teoria asintotica servire in quli casi in cui l'ampiezza campionaria e' molto grande. SI hanno dunque dei metodi per approsimare cio che aviene quando *n* e finito.\n",
        "\n",
        "Cominceremo della stima puntuale e, in particolare, defineremo delle proprieta desiderabili per gli stimatori vedremo poi quando queste proprieta sono soddisfatte.\n",
        "\n",
        "Una proprieta  molto intuitiva e':\n",
        "\n",
        "DEF: uno stimatore $T_n$ di un parametro $\\theta$ di dice CONSISTENTE se:\n",
        "$$lim_{n-> \\infty} P(|T_n - \\theta| < \\epsilon) = 1$$\n",
        "- for all $\\theta \\in \\Theta$\n",
        "\n",
        "Osservazioni:\n",
        "1. nelle definizioni delle proprieta asintotiche spesso lo stimatore e' indicato con $T_n$ per sottolineare il ruolo dell'ampiezza campionaria *n* - Propriamente, si tratta di una successione di stimatori. Inoltre, la definizione puo' essere data anche per una funzione $\\tau(\\theta)$ di $\\theta$ se essa e' l'oggetto della stima.\n",
        "\n",
        "2. Per verificare la consistenza si usa spesso la disuglgualianza di Chebyshev:\n",
        "$$P(|T_n - \\theta| < \\epsilon) >= 1- \\frac{E_{\\theta}[(T_n - \\theta)^2]}{\\epsilon^2}$$\n",
        "\n",
        "Pertanto, se $E_{\\theta[}(T_n-\\theta)^2]-< 0$ si il sisultato desiderato. Tuttavia ricordiamo che $E_{\\theta}[(T_n - \\theta)^2] = Var_{\\theta}(T_n) + [E_{\\theta} - \\theta]^2$\n",
        "\n",
        "Scomposizone dell'errore quadratico medio. cioe, due condizioni **sufficienti** per la consistenza sono:\n",
        "1. $lim_{n->\\infty} E_{\\theta}[T_n] = \\theta$\n",
        "2. $lim_{n->\\infty} Var_{\\theta}[T_n] = 0$ - for all $\\thea \\in \\Theta$\n",
        "\n",
        "ND: sonocondizoni sufficienti ma non necessiari. Talvolta si distinguera due tipo do consistenza: se valgono le due condizioni si ha consistenza in media quadratica che implica la consistenzain probabilita.\n",
        "\n",
        "Esempio:\n",
        "\n",
        "Un classico esempio riguarda la consistenza della media campionaria per un campione estratto da una popolazione con varinaza finita:\n",
        "- $X_1...X_n$ - iid con\n",
        "- $E(X_i)= \\mu$\n",
        "- $Var(X_i)= \\sigma^2 < \\infty$ - i=1...n\n",
        "- $\\bar{X}= 1/n \\sum_{i=1}^n X_i$\n",
        "\n",
        "Poiche come sapiamo: $E(\\bar{X}) = \\mu; Var(\\bar{X})= \\sigma^2 /n$\n",
        "\n",
        "si ha:\n",
        "\n",
        "- $lim_{n->\\infty} E[\\bar{X}] = \\mu$\n",
        "- $lim_{n->\\infty} Var[\\bar{X}] = 0$\n",
        "\n",
        "qundi $\\bar{X}$ e' consistente per $\\mu$\n",
        "\n",
        "Aggingiamo che se $X_1...X_n$ iid $\\sim N(\\mu, \\sigma^2)$ so avrebbe:\n",
        "\n",
        "$\\bar{X} \\sim N(\\mu; \\sigma^2/n)$\n",
        "\n",
        "ossia\n",
        "\n",
        "$\\sqrt{\\bar{X} - \\mu} \\sim N(0, \\sigma^2)$\n",
        "\n",
        "L'ulstima considerazione ci dice una cosa importante: nonstante il fatto che per avere la consistenza, uno buon stimatore abbia spesso una varianza che tende a zero per $n-> \\infty$, si ha anche spesso un fattore che \"stabilizza\" la varianza facendo si che tende ad un valore finito $\\ne 0$ spesso questo fattore e' $\\sqrt{n}$\n",
        "\n",
        "In molti cvasi, inoltre una varianza finita si po ottenere insieme ad una distribuizone Normale (almeno al limite, si non per ogni n come nell'esempio)\n",
        "\n",
        "CIo porta a fornire due definizioni (di cui la seconda e' senz altro piu rilevante) che hanno a che fare con il con partemente asintotico della varianza di uno stimatore\n",
        "\n",
        "Def-1: Se esiste una sequenza $k_n$ di costanti tali che:\n",
        "- $$lim_{n->\\infty} Var[k_n.T_n] = \\tau^2 < \\infty$$\n",
        "\n",
        "la qunatita $\\tau^2$ si dice VARIANZA LIMITE dello stimatore $T_n$\n",
        "\n",
        "Def-2: Se per uno stimatore $T_n$ si ha che\n",
        "$$ k_n(T_n - \\tau(\\theta)) ->Z-> N(0, \\sigma^2)$$\n",
        "\n",
        "allora la quantita $\\sigma^2$ e la VARIANZA ASINTOTICA dello stimatore $T_n$\n",
        "\n",
        "La second definizione e' piu importante proprieta perche si richiede anche la convergenza ad una distributione Normlae (normalita asintotica). QUesto fatto perche di concentrasi non solo sulla stimatore $T_n$ e sue paramtro $\\theta$, ma anche su loro funzione perche (in base al metodo Delta) si puo dedure facilemente anche la normalita aisntotiha di funzione di $T_n$\n",
        "\n",
        "Puo accadere inoltre che alcuni stimatori abbiano una varianza asintotica che raggiunge il limite inferiore di Cramer-Rao - Questo introduce un-ulteriore prossibilita di trovare stimatori ... (almeno asintoticamente)\n",
        "\n",
        "DEF: uno stimatore $T_n$ e' ASINTOTICAMENTE EFFICETE per $\\tau(\\theta)$ se\n",
        "- $\\sqrt{x}(T_n- \\tau(\\theta)) -> \\mathcal{Z}-> N(0, \\sigma^2(\\theta))$\n",
        "\n",
        "con\n",
        "\n",
        "$\\sigma^2(\\theta) = \\frac{[\\tau`(\\theta)]^2}{E_{\\theta}[\\frac{\\partial}{\\partial \\theta} log{f(X|\\theta)}]^2}$\n",
        "\n",
        "Notiamo che, nella definizione , il fattore che stabilizza la varianza deve essere $\\sqrt{n}$. Inoltre la varianza asintotica puo dipendere dal parametro, pur essendo chiaramente una quantita finita.\n",
        "\n",
        "Esempio:\n",
        "\n",
        "\n",
        "Consideriamo $X_1...X_n \\sim Bernoulli(\\theta)$ e $\\tau(\\theta)= \\theta$\n",
        "\n",
        "Sappiamo che per molti motivi, un buon stimatore di $\\theta$ e $\\bar{X}$ ANche se il risultato e' scontato, proviamo e veificare che sia asintoticamente efficiente.\n",
        "\n",
        "Abbiamo:\n",
        "- $\\tau`(\\theta)= 1$\n",
        "- $log(f(X|\\theta))= X.log(\\theta) + (1-X)log(1-\\theta)$\n",
        "- $\\frac{\\partial}{\\partial \\theta} log(f(X|\\theta)) = X/\\theta - \\frac{1-X}{1-\\theta}= \\frac{x-\\theta}{\\theta(1-\\theta)}$\n",
        "\n",
        "- $E_{\\theta}[[\\frac{\\partial}{\\partial \\theta} log(f(X|\\theta))]^2] = E_{\\theta}[\\frac{(X-\\theta)^2}{\\theta^2(1-\\theta)^2}]= \\frac{\\theta(1-\\theta)}{\\theta^2(1-\\theta)} = \\frac{1}{\\theta(1-\\theta)}$\n",
        "\n",
        "Pewrtanto , per l'efficienza asintotica dovremmo avere\n",
        "- $\\sqrt{n}(\\bar{X}-\\theta) -\\mathcal{Z}-> N(0; \\sigma^2(\\theta))$ con $\\sigma^2(\\theta)= \\theta(1-\\theta)$\n",
        "\n",
        "Ma e' esattamente quello che si ha perche, in base al teorema centrale del limite:\n",
        "\n",
        "$\\sqrt{n} \\frac{\\bar{X}-\\theta}{\\sqrt{\\theta(1-\\theta)}} -\\mathcal{Z}-> N(0,1)$\n",
        "\n",
        "In metodo Delta costituisca un importante strumento per verificare l'efficienza aassintotica di stimatori piu complessi.\n",
        "\n",
        "Ricordiamo che, secondo il metodo , data una funzione $g(\\theta)$ con $g`(\\theta) \\ne \\theta$ si ha:\n",
        "\n",
        "$\\frac{Y_n-\\theta}{\\sigma/\\sqrt{n}} -\\mathcal{Z}-> N(0,1)=> \\frc{g(Y_n)- g(\\theta)}{|g`(\\theta)|\\frac{\\theta}{\\sqrt{n}}} -\\mathcal{Z}-> N(0,1)$\n",
        "\n",
        "Ossia in termini piu vicini al contesto considerato.\n",
        "\n",
        "$\\sqrt{n}(Y_n -\\theta) -\\mathcal{Z}-> N(0, \\sigma^2)=> \\sqrt{n}[g(Y_n)- g(\\theta)-\\mathcal{Z}-> N(0, \\sigma_g^2)]$\n",
        "\n",
        "- con $\\sigma_g^2= [g`(\\theta)]^2\\sigma^2$\n",
        "\n",
        "Esempio: contiua:\n",
        "\n",
        "consideriamo ora $\\tau(\\theta)= \\theta(1-\\theta)$ e lo stimatore $T_n = \\bar{X}(1-\\bar{X})$ - E asintoticamente efficiente?\n",
        "\n",
        "Poinche: $g(\\theta)= \\theta(1-\\theta)= \\theta-\\theta^2$ e $g`(\\theta)= 1-2\\theta$ che e\\ $\\ne 0$ intanto che $\\theta \\ne 1/2$ si ha\n",
        "\n",
        "$\\sqrt{n}(\\bar{X})(1-\\bar{X})- \\theta(1-\\theta)-\\mathcal{Z}-> N(0, \\sigma_g^2(\\theta))$\n",
        "\n",
        "con $\\sigma_g^2(\\theta= (1-2\\theta)^2/theta(1-\\theta))==\\frac{\\tau`(\\theta)^2}{I(\\theta)}$\n",
        "\n",
        "e quindi lo stimatore e' asintoticamente efficiente e la sua varianza asintotica e quella sopra.\n",
        "\n",
        "Osservazioni:\n",
        "1. la varianza asintotica viene ragiunta , appunto asintoticamntte. Pertanto non e' detto che rappresenti una valutazone attendibile quando *n* e; finito: potrebbe cio, essere una sottostima della reale varianza.\n",
        "Nell esempio, se $\\theta$ e icino a 1/2 la varinaze e prativaente nulla, il che e' piutosto difficile  e meno che n non sia molto molto alto.\n",
        "\n",
        "2. l'esempio mostra che nonstante talvolta si possa stabilire che uno stimatore e' asintoticamente attuale non e' possibile dare una valutazione approssimativa della sua varianza in tutti casi. nell'esempio non ha si puo dira se $\\theta=1/2$ ma anche n generale poiche la varianza dipende da $\\theta$ e queesto non e' noto.\n",
        "\n",
        "3. nell esempio abbiamo trovato lo stimatore asintoticamente efficiente servendosi dell'intuito ma dobbiamo ricordare che $\\bar{X}$ e' anche lo stimatore di massima verosimiglianza nel modello bernouliano vale infatti questa teorema\n",
        "\n",
        "Teorema: Se il modello $f(x|\\theta)$ rispetta alcune condizioni di regolarita e $\\tau(\\theta)$ e' una funzione continua di $\\theta$, allora indicato con $\\hat{\\theta}$ lostimatrore di massima verosimiglianza di $\\theta$\n",
        "\n",
        "$\\tau(\\theta)$ e consitente, asintoticamente Normale , asintoticamnte efficiente per $\\tau(\\theta)$\n",
        "\n",
        "NB:\n",
        "- le condizioni di regolarita del modello sono molto spesso verificate, tuttavia sono esclisi i modelli il cui supporto dipende da $\\theta$\n",
        "\n",
        "- delle tre proprieta dello stimatore di MV l'efficienza asintotica e' quella piu rilevante poiche la rachiude tutte:\n",
        "  - Effciienza asintotica => Normalita asintotica + consistenza (e' facile mostrare che , se $\\T_n$ e asintoticamente efficeinte, $[T_n - \\tau(\\theta)]-\\mathcal{Z}-> 0$ e la convergenza in legge ad una costante equivale alla convergenza in probabilita)\n",
        "\n"
      ],
      "metadata": {
        "id": "yBcfJPZVhqFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Come precisato usare la varianza asintoticha per approssimare la varianza reale di uno stimatore che si sa essere asintoticamente efficiente (cme pr lo stimatore di MV) non e' sempre agevole- Nella formula:\n",
        "\n",
        "$Var(T_n)  \\approx \\frac{[\\tau`(\\theta)]^2}{n.E_{\\theta}[\\frac{\\partial}{\\partial \\theta} log(f(x|\\theta))^2]} = \\frac{[\\tau`(\\theta)]^2}{n.I(\\theta)}$\n",
        "\n",
        "Vi e' infatti la dipendenza da $\\theta$ e la necessita di calcolare l'esperessione dell'informazione di FIsher, cioe di un valore attesso non sempre semplice.\n",
        "\n",
        "Ci sono due modi di ovviane a queesti problemi:\n",
        "1. Sostituire $\\theta$ con lo stimatore di MV $\\hat{\\theta}$\n",
        "2. approsimare, il valore attesso al denominatore\n",
        "\n",
        "Se si usa solo la prima soluzione si ottiene\n",
        "\n",
        "$Var{T_n} \\approx \\frac{[\\tau`(\\theta)^2]_{\\theta=\\hat{\\theta}}}{n.I(\\hat{\\theta})}$\n",
        "\n",
        "dove $I(\\hat{\\theta})$ e detta spesso informazione di Fisher plug-in e richiede oviamente di conoscere l'espressione del valore attesso in funzione di $\\theta$\n",
        "\n",
        "Se si usa anche la seconda soluzione si puo considerare che in base alla legge dei grandi numeri un valore attesso si puo approsimare con una media campionari:\n",
        "\n",
        "$I(\\theta)= E_{\\\\theta}[\\frac{\\partial}{\\partial \\theta} log(f(x|\\theta))^2]= E_{\\theta}[-\\frac{\\partial^2}{\\partial \\theta^2} log(f(x|\\theta))] $ - come gia sappiamo\n",
        "\n",
        "- $ \\simeq -1/n \\sum_{i=1}^n \\frac{\\partial^2}{\\partial\\theta^2} log(f(x_i|\\theta))= \\hat{I}(\\theta)$\n",
        "\n",
        "Sostituendo ora a $\\theta$ lo stimatore di MV:\n",
        "\n",
        "$\\hat{I}(\\hat{\\theta})= -1/n \\sum_{i=1}^n \\frac{\\partial^2}{\\partial \\theta^2} log(f(x_i|\\theta))|_{\\theta=\\hat{\\theta}}$\n",
        "\n",
        "Pertanto si ha:\n",
        "$I_n(\\theta)= n.I(\\theta) \\simeq n.\\hat{I}(\\hat{\\theta})= -\\sum_{i=1}^n \\frac{\\partial^2}{\\partial \\theta^2} log(f(x_i|\\theta))|_{\\theta=\\hat{\\theta}}$\n",
        "\n",
        "\n",
        "Questa quantita e detta spesso Informazione di Fisher (de; Campione) Osservata. Da essa si ottiene la sequente approsimazione della varianza dello stimatore $T_n$\n",
        "\n",
        "$\\hat{Var}(T_n) = \\frac{[\\tau`(\\theta)^2|_{\\theta=\\hat{\\theta}}]}{n.\\hat{I}(\\hat{\\theta})}= ....= \\frac{[\\tau`(\\theta)^2|_{\\theta=\\hat{\\theta}}]}{-\\sum_{i=1}^n \\frac{\\partial^2}{\\partial \\theta^2} log(f(x_i|\\theta))|_{\\theta=\\hat{\\theta}}}$\n",
        "\n",
        "Esempio:\n",
        "\n",
        "Consideriamo un esempio elementare:\n",
        "\n",
        "$X_1...X_n$ iid $\\sim Poisson(\\theta)$ e $\\tau(\\theta)= \\theta$\n",
        "\n",
        "Per questo problema sappiamo che $\\hat{\\theta}= \\bar{X}$ cioe lo stimatore di MV che e' asintoticamente efficiente e' la media campionaria\n",
        "\n",
        "Il fatto che lo stimatore sia cosi semplice , ci permette naturalmente di calcolare in modo semplice la sua varianza: $Var_{\\theta}(\\bar{X})= \\theta/n$\n",
        "\n",
        "RImane tuttavia il problema dell'impossibilita di calcolare l'espresione sopre, poiche $\\theta$ non e' noto. Si po dunque pansare di sostiture $\\theta$ con $\\hat{\\theta}$ e colcolare una varianza plug-in\n",
        "\n",
        "$Var_{\\hat{\\theta}}(\\bar{X})= \\bar{X}/n$\n",
        "\n",
        "In questo esempio , allo stesso risultato si perviene se si applicano le technich di approsimazione della varianza viste sopra:\n",
        "1. se si determina l'inoformazione di Fisher e ci si limita a sostituire $\\theta$ con $\\hat{\\theta}$ si ottiene\n",
        "- $\\tau`(\\theta)=1$\n",
        "- $\\frac{\\partial^2}{\\partial \\theta^2} log(f(X|\\theta))= \\frac{\\partial^2}{\\partial \\theta}[\\theta.log(X)- \\theta - X!]= \\frac{\\partial}{\\partial \\theta}[\\frac{X}{\\theta} - 1] = -\\frac{X}{\\theta^2}$\n",
        "\n",
        "- $E[-\\frac{\\partial}{\\partial \\theta^2} log(f(X|\\theta))]= E[\\frac{X}{\\theta^2}]= \\frac{1}{\\theta^2}\\theta= \\frac{1}{\\theta} => \\hat{Var}(\\bar{X})= \\frac{1}{n.\\frac{1}{\\theta}}|_{\\theta=\\hat{\\theta}}= \\frac{\\bar{X}}{n}$\n",
        "\n",
        "\n",
        "2. Se si approssima anche l'informazione di Fisher, siottiene:\n",
        "\n",
        "- $\\frac{\\partial^2}{\\partial \\theta^2} log(f(X_i|\\theta))= -\\frac{X_i}{\\theta^2}$\n",
        "\n",
        "- $-\\frac{1}{n} \\sum_{i=1}^n log(f(X_i|\\theta)) = \\frac{1}{\\theta} \\sum_{i=1}^n X_i = \\frac{\\bar{X}}{\\theta^2}$\n",
        "\n",
        "- $n.\\hat{I}(\\theta) = \\frac{n.\\bar{X}}{\\theta^2}$\n",
        "\n",
        "- $n.\\hat{I}(\\hat{\\theta}) = \\frac{n.\\bar{X}}{\\bar{X^2}}= \\frac{n}{\\bar{X}}$\n",
        "\n",
        "=> $\\hat{Var}(\\bar{X}) = \\frac{1}{\\frac{n}{\\bar{X}}}= \\frac{\\bar{X}}{n}$\n",
        "\n"
      ],
      "metadata": {
        "id": "6WW8Q46ChqHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Approssimazione delle distribuzioni Campionarie Meiante simulazioni:\n",
        "\n",
        "Abbiamo visto che il ricorso alla teoria asintotica puo servire per approssimare la varianza di uno stimatore.\n",
        "\n",
        "Un metoo di approssimazione alternativo, che segua una logica completamnte diversa e' quelo basato sulle simulazion tramite il metodo Monte-Carlo. Abbiamo visto , infatti che e' possibile simulare il comportamento di una variabile aleatoria generando un numero elevato di valori derivanti dalla sua distribuzione . Poiche il campione e' una sequenza di variabili aleatoria, possiamo pensare di applicare il metodo Monte Carlo a tutti gli elementi del campione o a una loro funzione, cioe una statistica o uno stimatore.\n",
        "\n",
        "I risultati della simulazione dipendono, come comprensibile delle informaziooni di partenza. In alcvuni casi si puo parire da un modello statistico completamente noto. (anche per il valore dei parametri). Talvolta, invece, i parametri del modello non sono noti e non e' noto del tutto il modello statistico.\n",
        "\n",
        "va precisato inoltre che l'obbiettivo delle simulazion puo essere al varoianza dello stimatore , ma anche un'altra sua caratterstica?(o addotiva l'intera distribuzione campionaria)\n",
        "\n",
        "Distinguiamo diversi casi:\n",
        "\n",
        "1. Il moello statistico e' completamente noto.\n",
        "\n",
        "SI suppone di considerare un campione $X_1..X_n$ iid da un modello $f(x|\\theta)$\n",
        "completamente specificato (anche per $\\theta$) e una statistica: $T=T(X_1...X_n)$ la cui distibuzione campionaria , tuttavia e' difificile  da determinare. Pertanto occorre ricorrere a simulazioni:\n",
        "- fissato n , si generano M sequence IID dal modello $f(x|\\theta)$\n",
        "$$x_{1j}^*, x_{2j}^*... x_{nj}^*$$ i=1..n\n",
        "- par ogni sequnza si calcola il valore osservato di T: $t_i^*= T(t_{1i}^*, t_{2i}^*... t_{ni}^*)$ - i=1...M\n",
        "\n",
        "- si sintetizzano gli M valori ottenuti:\n",
        "$$\\bar{t}^*= \\frac{1}{M} \\sum_{i=1}^n t_i^*$$\n",
        "\n",
        "$$s_T^*= \\frac{1}{M-1} \\sum_{i=1}^M (t_i^* - \\bar{t}^*)^2$$\n",
        "\n",
        "la prima quantita e' un approsimazione di $E[T]$, la seconda di $Var{T}$\n",
        "\n",
        "NB: l'intera distribuzione di T potrebbe approssimata mediante l'instogramma degli M valori o mediante frequenza di specifici intervalli\n",
        "\n",
        "2. Il modello statistico e' noto, ma non e' noto il parametro (o i paramtri) che lo caratterizzano\n",
        "\n",
        "In questo cao, per poter generare osservazioni di $f(x|\\theta)$ e' ovviamente necessareio avere qualche informazione su $\\theta$.\n",
        "Spesso si assume di avere perlomeno una singola realizzazione campionaria , che verra utilizzata per ottenere (simulare) altre: si parla pertanto di metodi di RICAMPIONAMENTO . Nel caso specifico il metodo che consideramo viene detto BOOTSTRAP PARAMETRICO.\n",
        "\n",
        "- si stima $\\theta$ mediante la realizzazione compionaria osservata-> $\\hat{\\theta}$ (spesso si usa la stima di massima verosimiglianza)\n",
        "\n",
        "- fisato n, si generano M sequenze IID da $f(x|\\hat{\\theta})$\n",
        "\n",
        "$f(x|\\theta)$\n",
        "$$x_{1j}^*, x_{2j}^*... x_{nj}^*$$ i=1..M\n",
        "\n",
        "- si riportano i passi visti precedentemente\n",
        "\n",
        "3. Neanche il modello statistico e' noto:\n",
        "\n",
        " Chiaramente , anche in queesto caso dobbiamo perlomeno disporre di una realizzazione campionaria. Tuttavia questa non puo servire a stimare il modello statistico, perche questo non esiste. SI sa, tuttavia, che ciasuno dei dati ottenuti proviene dalla popolazione e potrebbe ripensantrsi se si generano altri dati dalla popolazione.\n",
        "\n",
        " SI decide , quindi di estrarre, casualmente e con reimissione, sequenza di n dati da $x_1,x_2..x_n$\n",
        "\n",
        "Cioe di effettuare un ricampionamento vero e proprio. SI parla di Bootstrap NON parametrioco.\n",
        "\n",
        "- si generano M sequenza:\n",
        "$f(x|\\theta)$\n",
        "$$x_{1j}^*, x_{2j}^*... x_{nj}^*$$ i=1..M\n",
        "estraentdo ogni volta n dati con reimissione da $x_1..x_n$\n",
        "\n",
        "- per ogni sequenza si cvalcola il valore osservato di T:\n",
        "$$t_i^* = T(x_{1i}^*, x_{2i}^*,..., x_{ni}^* ) $$ - i=1...M\n",
        "\n",
        "- si ripetono i passi precedenti\n",
        "\n",
        "Esempio: consideriamo n=4 e la seguente realizzazione campionaria: 11, 6, 23, 8\n",
        "\n",
        "inoltre consideriamo come stimatore la media campionaria: $\\bar{X}= \\frac{1}{4}(x_1+x_2+x_3+x_4)$\n",
        "\n",
        "Notiamo che la sue proprieta non sono scontate, poiche non abbiamo assunto niente riguardo alla popolazione.\n",
        "\n",
        "alcune delle sequenza ottenute dal bootstrap sono:\n",
        "- 6.11.11.8 => $t_1^*= 9$\n",
        "- 8,23,6,6 => $t_2^*= 10.75$\n",
        "- 11,23,8,6 => $t_3^*= 12$\n",
        "...\n",
        "\n",
        "qunte son in totale le sequenza ottenibili?\n",
        "\n",
        "Sono $4^4= 256$- Dunque in questo caso M=256\n",
        "\n",
        "L'esempio ci dice uno cosa molto importante. In generale, perche l'approssimazione ottnuta con le simulazioni si abuona, M deve essere un numero elevato. Nel caso del bootstrap non parametrico, tuttavia, l'ideale sarebbe oavere $M=n^n$. All aumentare di n , tale numero diventa velocemente poibitivo(per n=15 si ha $15^{15} \\sim (4.38).10^{17}$) e dunque bisogna scegliere un numero inferiore ma sufficiente elevato (tale numero e' il \"numero di campioni bootstrap\")\n",
        "\n",
        "Esempio:\n",
        "\n",
        "Per un campione $X_1...X_15$ con n=15 si considera la mediana campionaria: $T=X_{(8)}$\n",
        "\n",
        "data la realizzazione campionaria:\n",
        "- $-2,-0.2,-5.2,-3.5,-3.9$\n",
        "- $-0.6, -4.3, -1.7, -9.5, + 16$\n",
        "- $-2.9, +0.9, -1, -2 , +3$\n",
        "\n",
        "e stato implementao il metodo bootstrap e la varianza approssimata ottenuta col metodo e' stata:\n",
        "\n",
        "- $\\hat{Var}(T)= 0.770866$ - con M=  1000\n",
        "- $\\hat{Var}(T)= 0.718612$ - con M=10 000\n",
        "- $\\hat{Var}(T)= 0.704928$ - con M=100 000\n",
        "\n",
        "si nota come il valore tenda a stabilizzarsi - DUnque quello ottenuto per M=100 000 puo essere considerato una approssimazione attndibile.\n",
        "\n"
      ],
      "metadata": {
        "id": "3kMoidUohqN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intervalli di COnfidenza Asintotici:\n",
        "\n",
        "Poiche come sappiamo un intervallo di confidenza puo essere ottenuto invertendo la regione di accetazione di un test, alcuni intervallo di confidenza assintotici si possono ricavare dai metodi asintotici visti inprecedenza per i test. I piu utilizzati sono certamente quelli basati sul metodo di Wald, anche se non e' scontato che siano i migliori in temini di probabilita di copertura e di lungezza.\n",
        "\n",
        "Esempio:\n",
        "\n",
        "$X_1...X_n$ IID $\\sim Bernoulli(\\theta)--- 0< \\theta< 1$\n",
        "\n",
        "1. Utilizzando la regione di accettazione del test per $H_0: \\theta=\\theta_0$ contro $H_1: \\theta\\ne \\theta_0$ basato sulla distribuzione asintotica del rapporto di verosimiglianza, si dovra invertire rispetto a $\\theta_0$ l\\espressione\n",
        "\n",
        "$$-2.log[\\frac{\\theta_0^{\\sum x_i} (1-\\theta_0)^{n-\\sum x_i}}{\\bar{x}^{\\sum x_i} (1-\\bar{x})^{n-\\sum x_i}}] =< \\chi_{1;\\alpha}^2$$\n",
        "\n",
        "2. Utilizzando il corripsondente test di Wald basato sul fatto che\n",
        "\n",
        "$$\\frac{\\bar{X}-\\theta}{\\sqrt{\\frac{\\bar{X}(1-\\bar{X})}{n}}} -\\mathcal{Z}-> N(0,1)$$\n",
        "\n",
        "Si dovre invertire , rispetto a $\\theta_0$\n",
        "\n",
        "$$-Z_{\\alpha/2} < \\frac{\\bar{x} - \\theta_0}{ \\sqrt{\\frac{\\bar{x}(1-\\bar{x})}{n}}}  < Z_{\\alpha /2}$$\n",
        "\n",
        "queso e' lintervallo asintotico piu utilizzato:\n",
        "\n",
        "$\\bar{x} -+ z_{\\alpha/2} \\sqrt{\\frac{\\bar{x}(1-\\bar{x})}{n}}$\n",
        "\n",
        "\n",
        "3. Utilizzando lo score- test, si dovra invertire rispetto a $\\theta_0$\n",
        "\n",
        "\n",
        "$$-Z_{\\alpha/2} < \\frac{\\bar{x} - \\theta_0}{ \\sqrt{\\frac{\\theta_0(1-\\theta_0)}{n}}}  < Z_{\\alpha /2}$$\n",
        "\n",
        "NB: l'inversione non e' semplice. SUl casella-Berrger e'riportato il risultao e anche alcune simulazione per confronttre i tre intervalli\n",
        "\n"
      ],
      "metadata": {
        "id": "hyK-fvtThqSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Asintotici\n",
        "\n",
        "Assumere di poter contare su una numerosita campionaria elevata, puo talvolta aiutare nella ricerda di un test per un datp problema.\n",
        "\n",
        "Nonostante abbiamo infatti definito chiaramente cosa desideriamo per avere un test ottimale, talvolta, determiniamo non e' affatto semplice e possiamo accontentarci di avere perlomeno una approssimato.\n",
        "\n",
        "Vedrome tra metodi di ottenere un test approsimato basato sul assunzione di una numeorista elevata - teoricamente tenente all'infinito.\n",
        "\n",
        "1. test assintotici basati sulla distribuzione approsimatta del rapporto di verosimiglianza.\n",
        "\n",
        "sappiamo che il test del rapporto di verosimiglianza LRT ha la seguente regione di rifito\n",
        "\n",
        "$R == \\{ (x_1...x_n): \\lambda(\\vec{x}) =< c \\}$\n",
        "\n",
        "dove:\n",
        "\n",
        "$$\\lambda(\\vec{x})= \\frac{sup_{\\theta \\in \\Theta_0} L(\\theta|\\vec{x})}{sup_{\\theta \\in \\Theta} L(\\theta|\\vec{x})}$$\n",
        "\n",
        "Notiamo quello che possa sembrare ,il vero problema della sua applicazione non e' quello di deteminare il valore assunto dalla statistica $\\lambda(\\vec{x})$: talvolta si puo lavorare in funzione di altre statistiche piu conguiali , ma anche se cio non e' possibile i due \"sup\" del rapporto possono spesso essere determinati numericamnte usando i dati.\n",
        "\n",
        "Il vero problem e' invece la determinazione della \"soglia\" c\n",
        "\n",
        "$c - t.c. = sup_{\\theta \\in \\Theta_0 } P_{\\theta}(\\lambda(\\vec{x} =< c))= \\alpha$\n",
        "\n",
        "perche richiede la distribuzione campionaria $\\lambda(\\vec{x})$\n",
        "\n",
        "viene in aiuto tuttavia il seguente teorema che fornisce un approssimazione asintotica\n",
        "\n",
        "Teorema: Sia $X_1...X_n$ un campione IID estratto da una popolazione condistribuzione $f(x|\\theta)$ che sodisfa alcune condizioni di regolarita. SIa inoltre $\\theta$ un parametro reale e siano date le ipotesi:\n",
        "- $\\H_0: \\theta= \\theta_0$ contro $H_1: \\theta \\ne \\theta_0$\n",
        "\n",
        "Allora, sotto $H_0$ e per $n-> \\infty$ si ha\n",
        "$$-2 log(\\lambda (\\vec{x})) -\\mathcal{Z}-> \\chi_1^2$$\n",
        "\n",
        "NB: le condizioni di regolarita sono le stesse che assicurano la Normalita asintotica dello stimatore di massima verosimiglianza.\n",
        "\n",
        "Esempio:\n",
        "\n",
        "$X_1...X-n \\sim Poisson(\\theta)$  $\\theta > 0$\n",
        "\n",
        "$H_0: \\theta = \\theta_0$ vs $H_1: \\theta \\ne \\theta_0$\n",
        "\n",
        "- $p(x|\\theta)= \\frac{\\theta^x .e^{-\\theta}}{x!}$\n",
        "\n",
        "- $L(\\theta|\\vec{x}) = \\frac{\\theta^{\\sum x_i} . e^{-n\\theta}}{pi. x_i!}$\n",
        "e sappiamo che lo stimatore di MV e' la media campionaria - cioe\n",
        "\n",
        "$$sup_{\\theta \\in \\Theta} L(\\theta|\\vec{x})= \\frac{\\bar{x}^{\\sum x_i} . r^{-n\\bar{x}}}{pi. x_i!}$$\n",
        "\n",
        "Naturalmente inoltre:\n",
        "\n",
        "$$sup_{\\theta \\in \\Theta_0} L(\\theta|x)= L(\\theta_0|\\vec{x})= \\frac{\\theta_0^{\\sum x_i}.e^{-n.\\theta_0}}{pi.xi !}$$\n",
        "\n",
        "Pertanto:\n",
        "\n",
        "$\\lambda(\\vec{x}) = \\frac{\\theta^{x_i}.e^{-n.\\theta_0}}{\\bar{x}^{\\sum x_i}.e^{-n\\bar{x}}}= (\\frac{\\theta_0}{x_0})^{\\sum x_i}.e^{-n(\\theta_0-\\bar{x})}$\n",
        "\n",
        "\n",
        "$log{\\lambda(\\vec{x})}= \\sum x_i (log \\theta_0 - log \\bar{x}) - n(\\theta_0 - \\bar{x})$\n",
        "\n",
        "$-2 log \\lambda(\\vec{x}) = 2n[(\\theta_0-\\vec{x})- \\bar{x}(log \\theta_0 - log \\bar{x})]$\n",
        "\n",
        "Il teorema afferma che asintoticamente e sotto $H_0$\n",
        "\n",
        "$U(\\theta_0)= 2n[(\\theta_0 - \\bar{x}) - \\bar{x}(log \\theta_0 - log \\bar{x})] -\\mathcal{Z}-> \\chi_1^2$\n",
        "\n",
        "Possiamo dunque rifiutare $H_0$ quando\n",
        "\n",
        "$U(\\theta_0) >= \\xhi_{1'\\alpha}^2$ - percentile della chi-quadrato con 1 df\n",
        "\n",
        "Naturalmente, il parametro $\\theta$ puo essere vettoriale (ci sono cioe k parametri) e le due ipotesi $H_0$ e $H_1$ possono essere composte (ossia non precisono completamente il valore di alcuni parametri)\n",
        "\n",
        "In questo caso il teorema si puo cosi estendere\n",
        "\n",
        "$-2 log \\lambda(\\vec{x})-\\mathcal{Z}->\\chi_r^2$\n",
        "\n",
        "\n",
        "dove r=$n^0$ parametri speicificati da $H_0$- $n^0$ di parametri specificati da $H_1$\n",
        "\n",
        "NB: nel caso di $\\theta$ reale $r=1-0=1$\n",
        "\n",
        "\n",
        "Esempio:\n",
        "\n",
        "suppponiamo che ogni soggetto di un campione di individui debba rispondere ad una domanda di un questionario dove le risposte possibili sono quattro:\n",
        "- PN - per niente\n",
        "- PC - poco\n",
        "- AB - abbastanza\n",
        "- MT- molto\n",
        "\n",
        "ogni osservazione puo essere descritta come un vettore di zero e uno. Ad esempio un dato soggetto che ha risposto \"abbastanza\" avra\n",
        "\n",
        "- PN- 0 -> $x_{1j}= 0$\n",
        "- PC- 0 -> $x_{2j}= 0$\n",
        "- AB- 0 -> $x_{3j}= 1$\n",
        "- MT- 0 -> $x_{4j}= 0$\n",
        "\n",
        "ovviamente ci deve essere un solo 1\n",
        "\n",
        "Cioe: ogni osservazione e' un vvettore\n",
        "\n",
        "$\\vec{x_i}= (x_{1j}, x_{2j}, x_{3j}, x_{4j}) = (0,0,1,0)$\n",
        "\n",
        "E ogni realizzazione campionaria e' ottenuta con n di questi vettori\n",
        "\n",
        "$\\vec{x}= (\\vec{x_1}, \\vec{x_2}, ..., \\vec{x_n})$\n",
        "\n",
        "Dobbiamo capire quale modello statistico possiamo assegnare nello spazio campionario, ossia quale probabilita possiamo assegnare ad ogni realizzazione campionaria e da quali parametri dipende questa probabilita.\n",
        "\n",
        "La probabilita che l'individuo i-esimo dia una specifica risposta dipende dalle probabilita che ci sono per ciasuna di esse - Se possiamo\n",
        "\n",
        "- $P(PN=P_1), P(PC)=P_2; P(AB)=P_3,, P(MT)=P_4$\n",
        "\n",
        "- $P(\\text{individuo --esimo riusposta \"AB\"})= P_3= (P_1)^0, (P_2)^0, (P_3)^1.(P_4)^0$\n",
        "$= P(\\vec{x_i})= (0,0,1,0)= P(\\vec{x_i}= x_i)$\n",
        "\n",
        "Cioe, per ogni elemento del campione si puo scegliere il modello - MULTINOMIALE\n",
        "\n",
        "$P(\\vec{X_i}= \\vec{x_i})= P_1^{x_{1j}}.P_2^{x_{2j}}.P_3^{x_{3j}}.P_4^{x_{4j}}$\n",
        "\n",
        "essendo:\n",
        "- $P_1+P_2+P_3+P_4=1$\n",
        "- $x_{1j}, x_{2j}, x_{3j}, x_{4j}$ tutti \"0\" tranne uno che vale 1\n",
        "\n",
        "Ora si puo scrivere la funzione di verosimiglianza considerata una realizzazione campionaria\n",
        "\n",
        "$\\vec{x}= (\\vec{x_1}, \\vec{x_2}...\\vec{x_n})$ e posto $\\vec{\\theta}= (P_1,P_2,P_3,P_4)$\n",
        "\n",
        "$L(\\vec{\\theta}|\\vec{x}) = \\prod_{i=1}^n P_1^{x_{1j}}, P_2^{x_{2j}}, P_3^{x_{3j}}, P_4^{x_{4j}}= P_1^{\\sum x_{1j}}. P_2^{\\sum x_{2j}}. P_3^{\\sum x_{3j}}. P_4^{\\sum x_{4j}}$\n",
        "\n",
        "$\\sum_{i=1}^n x_{1j}$ e' dunque il numero di individui nel campione che hanno dato pa prima risposta PN\n",
        "\n",
        "Analogamente per altre risposte.\n",
        "\n",
        "E possiamo:\n",
        "\n",
        "$\\sumx_{1i}= y_1, \\sumx_{2i}= y_1, \\sumx_{3i}= y_1, \\sumx_{4i}= y_1$\n",
        "\n",
        "ottenendo pertanto\n",
        "\n",
        "$L(\\vec{\\theta}|\\vec{x})= P_1^{y1}.P_2^{y2}.P_3^{y3}.P_4^{y}$\n",
        "\n",
        "Ora supponiamo di voler svilupare un test LRT asintotico per le ipotesi:\n",
        "\n",
        "$H_0: (P_1=P_4) \\cap (P_2 =P_3)$\n",
        "\n",
        "$H_1$: non e' vera $H_0$\n",
        "\n",
        "$H_0$ significa cioe che esiste una \"simetria \" nelle quatro risposte.\n",
        "\n",
        "E chiaro che in generale il modello scelto ha 3 parametri (cioe spazio parametrico ha 3 dimensioni). Infatti una volta note, ad esempio $P_1.P_2,P_3,P_4$ e' unovocamente determinato come $1-P_2-P_3-P_4$\n",
        "\n",
        "la dimensione dello spazio parametrico sotto $H_0$ e' invece pari ad 1. Infatti , se e' vera $H_0$ e ad esempio e' note $p_1$ si ha\n",
        "\n",
        "$P_4=P_1$ e $P_2=P_3= \\frac{1-2p_1}{2}= 1/2-P_1$\n",
        "\n",
        "Ora calcoliamo il rapporto delle verosimiglianza . Al denomiatore avremo:\n",
        "\n",
        "$suo_{\\Theta} L(\\theta|\\vec{x})= sup_{(P_1,P_2,P_3,P_4)} [ P_1^{y_1}P_2^{y_2}P_3^{y_3}P_4^{y_4}]$\n",
        "\n",
        "Si tratta, insostanza di massimizzazione la funzione di verosimiglianza rispetto ai quattro parametri. Semplicemente un po, se dovessimo massimizzare solo rispetto a $P_1$ dovremmo massimizzare:\n",
        "\n",
        "$L(P_1)= P_1^{y_1}P_2^{y_2}P_3^{y_3}P_4^{y_4}= P_1^{y_1}(1-P_1)^{n-y_1}$\n",
        "\n",
        "$log L(P_1)= y_1 log P_1 + (n-y_1) log(1-P_1) \\frac{d log L(p_1)}{d p_1}= \\frac{y_1}{p_1} - \\frac{n-y_1}{1-p_1}$\n",
        "\n",
        "$(1-p_1)y_1 - p_1(n-y_1)= 0$\n",
        "\n",
        "$y_1 - y_1p_1 - np_1 - y_1p_1= 0$\n",
        "\n",
        "$y_1 - np_1 = 0$\n",
        "\n",
        "$\\hat{p_1}= \\frac{y_1}{n}$\n",
        "\n",
        "E la derivativa seconda e' sempre negativa.\n",
        "\n",
        "QUindi la stima di massima verosimiglianza di $p_1$ e' la proporzione di soggetti nel campione che dannno la risposta ON\n",
        "\n",
        "Analogamente le stime degli altri parametir sono le corrispondenti proporzioni campionaria:\n",
        "\n",
        "$\\hat{P_2}= \\frac{y_2}{n}; \\hat{P_3}= \\frac{y_3}{n}; \\hat{P_2}= \\frac{y_2}{n}= 1- \\hat{P_1}-\\hat{P_2}-\\hat{P_3}$\n",
        "\n",
        "Pertanto:\n",
        "\n",
        "$sup_{\\theta \\in \\Theta} L(\\vec{\\theta}|\\vec{x})= (\\frac{y_1}{n})^{y_1}.(\\frac{y_2}{n})^{y_2}.(\\frac{y_3}{n})^{y_3}.(\\frac{y_4}{n})^{y_4}$\n",
        "\n",
        "al numeratore del rapporto di verosimiglianza dobbiamo invece calcolare\n",
        "\n",
        "$sup_{\\theta \\in \\Theta_0}L(\\vec{\\theta}|\\vec{x})= sup[P_1^{y_1}.(\\frac{1}{2}-P_1)^{y_2}.  (\\frac{1}{2}-P_1)^{y_3}P_1^{y_4} ] = sup_{p_1}[P_1^{y_1+y_4}(\\frac{1}{2}^{y_2+y_3})]$\n",
        "\n",
        "derivando il log dell espressione tra parentesi si ha\n",
        "\n",
        "$\\frac{y_1+y_4}{P_1} - \\frac{y_2+y_3}{\\frac{1}{2} -P_1}= 0$\n",
        "\n"
      ],
      "metadata": {
        "id": "DE-SvHkOhqUY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$(\\frac{1}{2} - P_1)(y_1+y_4) - P_1(y_2+y_3)=0$\n",
        "\n",
        "$\\frac{1}{2} (y_1+y_4) -P_1(y_1+y_4+y_2+y_3)= 0$\n",
        "\n",
        "$\\frac{1}{2}(y_1 +y_4) -np_1=0$\n",
        "\n",
        "$\\hat{P_1}= \\frac{y_1 + y_4}{2n}$ - la derivata seconda e' negativa\n",
        "\n",
        "e dunque\n",
        "\n",
        "$sup_{\\theta \\in \\Theta_0} L(\\vec{\\theta}|\\vec{x})= (\\frac{y_1 + y_4}{2n}^{y_1+y_4}) (\\frac{1}{2}- \\frac{y_1+y_4}{2n})^{y_2+y_3}$\n",
        "\n",
        "ora si calcola\n",
        "\n",
        "$\\frac{sup_{\\theta \\in \\Theta_0} L(\\vec{\\theta}|\\vec{x})}{sup_{\\theta \\in \\Theta} L(\\vec{\\theta}|\\vec{x})}$\n",
        "\n",
        "$(\\frac{y_1 + y_4}{2y_1})^{y_1} (\\frac{n-y_1-y_4}{2y_2})^{y_2}(\\frac{n-y_1-y_4}{2y_3})^{y_3}. (\\frac{y_1 + y_4}{2y_4})^{y_4}$\n",
        "\n",
        "Ponendo:\n",
        "\n",
        "$Y^* = \\frac{y_1+y_4}{2} => \\frac{y}{2} -y^* = \\frac{y_2+y_3}{2}$\n",
        "\n",
        "si ha\n",
        "\n",
        "$-2.log \\lambda(\\vec{x})= -2[y_1 log\\frac{y^*}{y_1} + y_2 log \\frac{n/2 -y^*}{y_2} + y_3 log \\frac{n/2 -y^*}{y_3} + y_4 log\\frac{y^*}{y_4}]$\n",
        "\n",
        "$2y_1 log \\frac{y_1}{y^*} + 2 y_2 log \\frac{y_2}{n/2-y^*} + 2 y_3 log \\frac{y_3}{n/2-y^*} + 2 y_4 log \\frac{y_4}{y^*}$\n",
        "\n",
        "E risulta che:\n",
        "\n",
        "$-2 log \\lambda(\\vec{x}) -\\mathcal{Z}-> \\chi_2^2 $\n",
        "\n",
        "da cio ;a regione critica:\n",
        "\n",
        "$R == [(\\vec{x_1}), ..., (\\vec{x_n}) : \\lambda(\\vec{x} > \\chi_{2;\\alpha}^2)]$"
      ],
      "metadata": {
        "id": "zYZzAfkvhqWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Test di WALD:\n",
        "\n",
        "Talvolta un test asintotico puo essere basata su una statistica di cui si sa che possiede una distribuzione asintotica Normale. Ad eempio usando il teoreme centrale del limite o perche la statistica e' uno stimatore di MV.\n",
        "\n",
        "Supponiamo di avere:\n",
        "\n",
        "$H_0: \\theta=\\theta_0$ vs $H_0: \\theta \\ne \\theta_0$\n",
        "\n",
        "e suponniamo che per ogni $\\theta$ la statistica $W_n$ sia tale che\n",
        "\n",
        "$\\frac{W_n-\\theta}{\\sigma_n} -\\mathcal{Z}-> N(0,1)$\n",
        "\n",
        "dove $\\sigma_n = \\sqrt{Var(W_n)}$ e la deviazione standard di $W_n$\n",
        "\n",
        "\n",
        "Notiamo che il repporto sopra dipende da $\\theta$ anche $\\sigma_n$ tra l'altro , potrebbe dipendere da $\\\n",
        "theta$. Tuttavia possiamo usare il risultato sopra sotto $H_0$ e conludere che la \"nuova\" statistica\n",
        "\n",
        "$z_n^` = \\frac{W_n - \\theta_0}{\\sigma_n} -\\mathcal{Z}-> N(0,1)$ sotto $H_0$\n",
        "\n",
        "Costruendo cosi la regione di rifiuto:\n",
        "\n",
        "$R  \\equiv \\{ (x_1...x_n): (z_n^` \\leq -z_{\\alpha/2}) \\cap (z_n^` \\geq z_{\\alpha/2})\\}$\n",
        "\n",
        "NB: $z_{\\alpha/2}$ e un [ercentile di N(0,1)\n",
        "\n",
        "Talvolta , tuttavia questa procedura non puo essere applicata perche $\\sigma_n$ dipende da altri parametri (oltre a $\\theta$) e questi non sono noti. Cioe $z_n^`$ non e' una statistica.\n",
        "\n",
        "Si cerca allora di sostituire $\\sigma_n$ con un su stimatore consistente: $S_n$\n",
        "\n",
        "$S_n \\text{ tale che } \\frac{S_n}{\\sigma_n}  \\overset{P}{\\to}  {0}$\n",
        "\n",
        "NB: $S_n$ viene spesso detto STANDARD ERROR di $W_n$\n",
        "\n",
        "Utilizzando il teorema di Slutisky, si ha sotto $H_0$\n",
        "\n",
        "$Z_n= \\frac{W_n - \\theta_0}{S_n} \\overset{Z}{\\to} N(0,1)$\n",
        "\n",
        "E la regione di rifiuto asintotica e'\n",
        "\n",
        "$R  \\equiv \\{ (x_1...x_n): (z_n \\leq -z_{\\alpha/2}) \\cup (z_n \\geq z_{\\alpha/2})\\}$"
      ],
      "metadata": {
        "id": "mFH-BjzvhqYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esempio:\n",
        "\n",
        "consideriamo un campione estratto da una popolazione X la cui distribuzione e' ignota ,ma si sa solo che:\n",
        "\n",
        "$E[X]=\\mu; Var[X]= \\sigma^2 <\\infty$\n",
        "\n",
        "Il teorema centrale del limite afferma che, comunque sia strutturato la popolazione, la media campionaria e' asintoticamente Normale:\n",
        "\n",
        "$\\frac{\\bar{X_n} -\\mu}{\\frac{\\sigma}{\\sqrt{n}}} \\overset{Z}{\\to} N(0,1)$\n",
        "\n",
        "Qui, dunque $\\sigma_n = \\frac{\\sigma}{\\sqrt{n}}$ che, come vediamo dipende da un altro parametro incognito $\\sigma$, di modo che $z_n^`$ non e' una statistica.\n",
        "\n",
        "Tuttavia sappiamo che se usiamo  la varianza campionaria:\n",
        "\n",
        "$S^2 = \\frac{1}{n-1} \\sum (x_i - \\\\bar{x})^2$\n",
        "\n",
        "ND: non e' lo stesso $S_n$ delle formulazione generale\n",
        "\n",
        "$S_n \\overset{P}{\\to} \\sigma$\n",
        "\n",
        "e anche\n",
        "\n",
        "$z_n = \\frac{\\bar{X_n}- \\mu}{S_n / \\sqrt{n}} \\overset{Z}{\\to} N(0,1)$\n",
        "\n",
        "NB: lo standard error di $\\bar{X_n} e\\ dunque $S_n /\\sqrt{n}$$\n",
        "\n",
        "Per cui il test di Wald ha regione critica:\n",
        "\n",
        "$R \\equiv \\{(x_1...x_n): (\\frac{\\bar{x_n}-\\mu_0}{\\frac{s_n}{\\sqrt{n}} } \\leq -z_{\\alpha/2}) \\cup (\\frac{\\bar{x_n}-\\mu_0}{\\frac{s_n}{\\sqrt{n}} } \\geq z_{\\alpha/2})$\n",
        "\n",
        "che e' un test asintotico molto utilizzato\n",
        "\n",
        "NOTA: in base al teorema sulle proprieta asintotiche degli stimatori di MV, il test di Wald puo, essere anche costruito usando $W_n$, lo stimatore di MV di $\\theta$ - lo standard error da utilizzare puo essere\n",
        "\n",
        "$\\frac{1}{\\sqrt{n.I(W_n)}}$ oppure $\\frac{1}{\\sqrt{n.\\hat{I}(W_n)}}$\n",
        "\n",
        "in base a quanto detto in precedenza NB: si usa $W_n$, lo stimatore non $\\\n",
        "hat{\\sigma}$ la stima perche si sta costruendo una statistica\n",
        "\n",
        "\n",
        "Nota 2: il vantaggio del metodo di Wald e' che si puo applicare anche per altrrernative \"unilaterali\" ad esempio:\n",
        "\n",
        "$H_0: \\theta \\leq \\theta_0$ vs $H_1: \\theta > \\theta_0$\n",
        "\n"
      ],
      "metadata": {
        "id": "dbOvALcAhqa1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jhg4tEQlhqdG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "a3XqqPguhqfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Score test\n",
        "\n",
        "\n",
        "Gli score test sono basati su unrisultato asintotichi che riguarda la score function  ossia ala funzione che viene posta uguale a Zero nel processo di derivazione degli stimatori di MV\n",
        "\n",
        "$\\frac{\\partial}{\\partial \\theta} log L(\\theta|\\vec{x})$\n",
        "\n",
        "Ricordiamo, infarri, che nell dimostrazione della disugualinza di Cramer- Rao-Frechet abbiamo fatto riferimento alla variabile\n",
        "\n",
        "$U = \\frac{\\partial}{\\partial \\theta} log f(\\vec{x}|\\theta) = \\frac{\\partial}{\\partial \\theta} log \\prod_{i=1}^n f(x_i|\\theta)$\n",
        "\n",
        "e mostranno che\n",
        "$E[U]= 0; Var[U]= u.I(\\theta)$\n",
        "\n",
        "Indicando $U=U[\\theta]$ per maggiore precisione, poiche dipende da $\\theta$, si puo anche mostrare che\n",
        "\n",
        "$\\frac{U(\\theta)}{\\sqrt{n.I(\\theta)}} \\overset{Z}{\\to} N(0,1)$\n",
        "\n",
        "Consideriamo ora  le ipotesi:\n",
        "\n",
        "$H_0: \\theta=\\theta_0$ vs $H_1: \\theta_ \\ne \\theta_0$\n",
        "\n",
        "Si ha sotto $H_0$\n",
        "\n",
        "$Z_n = \\frac{U(\\theta)}{\\sqrt{nI(\\theta_0)}} \\overset{Z}{\\to} N(0,1)$\n",
        "\n",
        "e $Z_n$ puo essere usato come statistica test con regione di rifiuto:\n",
        "\n",
        "$R  \\equiv \\{ (x_1...x_n): (z_n \\leq -z_{\\alpha/2}) \\cup (z_n \\geq z_{\\alpha/2})\\}$\n"
      ],
      "metadata": {
        "id": "rZz7Vygwhqlv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esempio:\n",
        "\n",
        "$X_1...X_n \\sim Bernoulli(\\theta)$\n",
        "\n",
        "\n",
        "$H_0: \\theta=\\theta_0$ vs $H_1: \\theta_ \\ne \\theta_0$\n",
        "costruiamo lo score-test\n",
        "\n",
        "- $p(x|\\theta)= \\theta^x (1-\\theta)^{1-x}$\n",
        "\n",
        "- $p(x|\\theta)= \\theta^{\\sum x_i} (1-\\theta)^{n-\\sum x_i}$\n",
        "\n",
        "- $log p(\\vec{x}|\\theta) = \\sum x_i log \\theta - (n- \\sum x_i)log(1-\\theta)$\n",
        "\n",
        "- $\\frac{\\partial}{\\partial \\theta} log p(\\vec{x}|\\theta)= \\frac{\\sum x_i}{\\theta} + \\frac{n- \\sum x_i}{\\theta}$\n",
        "\n",
        "$\\frac{(1-\\theta)\\sum x_i + \\theta(n - \\sum x_i)}{\\theta(1-\\theta)}$\n",
        "\n",
        "$= \\frac{\\sum x_i - n\\theta}{\\theta(1-\\theta)} = \\frac{n(\\bar{x}-\\theta)}{\\theta(1-\\theta)}$\n",
        "\n",
        "- $I(\\theta) = E_{\\theta}[(\\frac{x-\\theta}{\\theta(1-\\theta)})^2] = \\frac{1}{\\theta^2(1-\\theta)^2} . E_{\\theta}[(x-\\theta)^2]$\n",
        "\n",
        "\n",
        "$\\frac{1}{\\theta^2(1-\\theta)^2}Var_{\\theta}(x)$\n",
        "\n",
        "$\\frac{1}{\\theta^2(1-\\theta)^2} . \\theta(1-\\theta)= \\frac{1}{\\theta(1-\\theta)}$\n",
        "\n",
        "$z_n = \\frac{\\frac{n(\\bar{X}-\\theta_0) }{\\theta_0(1-\\theta_0) } }{\\sqrt{\\frac{n}{\\theta_0 (1-\\theta_0)}}  } = \\frac{\\bar{X}-\\theta_0}{\\sqrt{\\frac{\\theta_0(1-\\theta_0)}{n}}} \\overset{Z}{\\to N(0,1)}$\n",
        "\n",
        "che produce il classico test asintotico:\n",
        "\n",
        "$R  \\equiv \\{ (x_1...x_n): (\\frac{\\bar{x}-\\theta_0}{\\sqrt{\\frac{\\theta_0(1-\\theta_0)}{n}}} \\leq -z_{\\alpha/2}) \\cup (\\frac{\\bar{X}-\\theta_0}{\\sqrt{\\frac{\\theta_0(1-\\theta_0)}{n}}} \\geq z_{\\alpha/2})\\}$"
      ],
      "metadata": {
        "id": "xBQcJ_dRqcT8"
      }
    }
  ]
}