{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu+zhoBJHU70w4Y/l5KN/r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikolayLenkovNikolaev/Inferential_Statistics/blob/main/10_1_Borroni_Asimptotic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xDddhISAhp_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "y6KLPD2ihqCn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teoria Asintotica degli stimatori\n",
        "\n",
        "COme abbiamo visto (Legge dei grandi numeri, Teorema centrale del limite) quando l'ampiezza campionaria tende all'infinito si possono ricavare importanti proprieta degli stimatori inferenziali: si parla di proprieta asintotiche.\n",
        "\n",
        "Per cli sitmatori , questa e' un occassione per disporre di un ulteriore criterio di scelta. In particolare, come vedreo, gli stimatori di massima verosimilianza godono di proprieta che alti stimatori non hanno.\n",
        "\n",
        "Nella pritica , non potremo mai dispore di campioni con ampiezza infinita. Tuttavia la teoria asintotica servire in quli casi in cui l'ampiezza campionaria e' molto grande. SI hanno dunque dei metodi per approsimare cio che aviene quando *n* e finito.\n",
        "\n",
        "Cominceremo della stima puntuale e, in particolare, defineremo delle proprieta desiderabili per gli stimatori vedremo poi quando queste proprieta sono soddisfatte.\n",
        "\n",
        "Una proprieta  molto intuitiva e':\n",
        "\n",
        "DEF: uno stimatore $T_n$ di un parametro $\\theta$ di dice CONSISTENTE se:\n",
        "$$lim_{n-> \\infty} P(|T_n - \\theta| < \\epsilon) = 1$$\n",
        "- for all $\\theta \\in \\Theta$\n",
        "\n",
        "Osservazioni:\n",
        "1. nelle definizioni delle proprieta asintotiche spesso lo stimatore e' indicato con $T_n$ per sottolineare il ruolo dell'ampiezza campionaria *n* - Propriamente, si tratta di una successione di stimatori. Inoltre, la definizione puo' essere data anche per una funzione $\\tau(\\theta)$ di $\\theta$ se essa e' l'oggetto della stima.\n",
        "\n",
        "2. Per verificare la consistenza si usa spesso la disuglgualianza di Chebyshev:\n",
        "$$P(|T_n - \\theta| < \\epsilon) >= 1- \\frac{E_{\\theta}[(T_n - \\theta)^2]}{\\epsilon^2}$$\n",
        "\n",
        "Pertanto, se $E_{\\theta[}(T_n-\\theta)^2]-< 0$ si il sisultato desiderato. Tuttavia ricordiamo che $E_{\\theta}[(T_n - \\theta)^2] = Var_{\\theta}(T_n) + [E_{\\theta} - \\theta]^2$\n",
        "\n",
        "Scomposizone dell'errore quadratico medio. cioe, due condizioni **sufficienti** per la consistenza sono:\n",
        "1. $lim_{n->\\infty} E_{\\theta}[T_n] = \\theta$\n",
        "2. $lim_{n->\\infty} Var_{\\theta}[T_n] = 0$ - for all $\\thea \\in \\Theta$\n",
        "\n",
        "ND: sonocondizoni sufficienti ma non necessiari. Talvolta si distinguera due tipo do consistenza: se valgono le due condizioni si ha consistenza in media quadratica che implica la consistenzain probabilita.\n",
        "\n",
        "Esempio:\n",
        "\n",
        "Un classico esempio riguarda la consistenza della media campionaria per un campione estratto da una popolazione con varinaza finita:\n",
        "- $X_1...X_n$ - iid con\n",
        "- $E(X_i)= \\mu$\n",
        "- $Var(X_i)= \\sigma^2 < \\infty$ - i=1...n\n",
        "- $\\bar{X}= 1/n \\sum_{i=1}^n X_i$\n",
        "\n",
        "Poiche come sapiamo: $E(\\bar{X}) = \\mu; Var(\\bar{X})= \\sigma^2 /n$\n",
        "\n",
        "si ha:\n",
        "\n",
        "- $lim_{n->\\infty} E[\\bar{X}] = \\mu$\n",
        "- $lim_{n->\\infty} Var[\\bar{X}] = 0$\n",
        "\n",
        "qundi $\\bar{X}$ e' consistente per $\\mu$\n",
        "\n",
        "Aggingiamo che se $X_1...X_n$ iid $\\sim N(\\mu, \\sigma^2)$ so avrebbe:\n",
        "\n",
        "$\\bar{X} \\sim N(\\mu; \\sigma^2/n)$\n",
        "\n",
        "ossia\n",
        "\n",
        "$\\sqrt{\\bar{X} - \\mu} \\sim N(0, \\sigma^2)$\n",
        "\n",
        "L'ulstima considerazione ci dice una cosa importante: nonstante il fatto che per avere la consistenza, uno buon stimatore abbia spesso una varianza che tende a zero per $n-> \\infty$, si ha anche spesso un fattore che \"stabilizza\" la varianza facendo si che tende ad un valore finito $\\ne 0$ spesso questo fattore e' $\\sqrt{n}$\n",
        "\n",
        "In molti cvasi, inoltre una varianza finita si po ottenere insieme ad una distribuizone Normale (almeno al limite, si non per ogni n come nell'esempio)\n",
        "\n",
        "CIo porta a fornire due definizioni (di cui la seconda e' senz altro piu rilevante) che hanno a che fare con il con partemente asintotico della varianza di uno stimatore\n",
        "\n",
        "Def-1: Se esiste una sequenza $k_n$ di costanti tali che:\n",
        "- $$lim_{n->\\infty} Var[k_n.T_n] = \\tau^2 < \\infty$$\n",
        "\n",
        "la qunatita $\\tau^2$ si dice VARIANZA LIMITE dello stimatore $T_n$\n",
        "\n",
        "Def-2: Se per uno stimatore $T_n$ si ha che\n",
        "$$ k_n(T_n - \\tau(\\theta)) ->Z-> N(0, \\sigma^2)$$\n",
        "\n",
        "allora la quantita $\\sigma^2$ e la VARIANZA ASINTOTICA dello stimatore $T_n$\n",
        "\n",
        "La second definizione e' piu importante proprieta perche si richiede anche la convergenza ad una distributione Normlae (normalita asintotica). QUesto fatto perche di concentrasi non solo sulla stimatore $T_n$ e sue paramtro $\\theta$, ma anche su loro funzione perche (in base al metodo Delta) si puo dedure facilemente anche la normalita aisntotiha di funzione di $T_n$\n",
        "\n",
        "Puo accadere inoltre che alcuni stimatori abbiano una varianza asintotica che raggiunge il limite inferiore di Cramer-Rao - Questo introduce un-ulteriore prossibilita di trovare stimatori ... (almeno asintoticamente)\n",
        "\n",
        "DEF: uno stimatore $T_n$ e' ASINTOTICAMENTE EFFICETE per $\\tau(\\theta)$ se\n",
        "- $\\sqrt{x}(T_n- \\tau(\\theta)) -> \\mathcal{Z}-> N(0, \\sigma^2(\\theta))$\n",
        "\n",
        "con\n",
        "\n",
        "$\\sigma^2(\\theta) = \\frac{[\\tau`(\\theta)]^2}{E_{\\theta}[\\frac{\\partial}{\\partial \\theta} log{f(X|\\theta)}]^2}$\n",
        "\n",
        "Notiamo che, nella definizione , il fattore che stabilizza la varianza deve essere $\\sqrt{n}$. Inoltre la varianza asintotica puo dipendere dal parametro, pur essendo chiaramente una quantita finita.\n",
        "\n",
        "Esempio:\n",
        "\n",
        "\n",
        "Consideriamo $X_1...X_n \\sim Bernoulli(\\theta)$ e $\\tau(\\theta)= \\theta$\n",
        "\n",
        "Sappiamo che per molti motivi, un buon stimatore di $\\theta$ e $\\bar{X}$ ANche se il risultato e' scontato, proviamo e veificare che sia asintoticamente efficiente.\n",
        "\n",
        "Abbiamo:\n",
        "- $\\tau`(\\theta)= 1$\n",
        "- $log(f(X|\\theta))= X.log(\\theta) + (1-X)log(1-\\theta)$\n",
        "- $\\frac{\\partial}{\\partial \\theta} log(f(X|\\theta)) = X/\\theta - \\frac{1-X}{1-\\theta}= \\frac{x-\\theta}{\\theta(1-\\theta)}$\n",
        "\n",
        "- $E_{\\theta}[[\\frac{\\partial}{\\partial \\theta} log(f(X|\\theta))]^2] = E_{\\theta}[\\frac{(X-\\theta)^2}{\\theta^2(1-\\theta)^2}]= \\frac{\\theta(1-\\theta)}{\\theta^2(1-\\theta)} = \\frac{1}{\\theta(1-\\theta)}$\n",
        "\n",
        "Pewrtanto , per l'efficienza asintotica dovremmo avere\n",
        "- $\\sqrt{n}(\\bar{X}-\\theta) -\\mathcal{Z}-> N(0; \\sigma^2(\\theta))$ con $\\sigma^2(\\theta)= \\theta(1-\\theta)$\n",
        "\n",
        "Ma e' esattamente quello che si ha perche, in base al teorema centrale del limite:\n",
        "\n",
        "$\\sqrt{n} \\frac{\\bar{X}-\\theta}{\\sqrt{\\theta(1-\\theta)}} -\\mathcal{Z}-> N(0,1)$\n",
        "\n",
        "In metodo Delta costituisca un importante strumento per verificare l'efficienza aassintotica di stimatori piu complessi.\n",
        "\n",
        "Ricordiamo che, secondo il metodo , data una funzione $g(\\theta)$ con $g`(\\theta) \\ne \\theta$ si ha:\n",
        "\n",
        "$\\frac{Y_n-\\theta}{\\sigma/\\sqrt{n}} -\\mathcal{Z}-> N(0,1)=> \\frc{g(Y_n)- g(\\theta)}{|g`(\\theta)|\\frac{\\theta}{\\sqrt{n}}} -\\mathcal{Z}-> N(0,1)$\n",
        "\n",
        "Ossia in termini piu vicini al contesto considerato.\n",
        "\n",
        "$\\sqrt{n}(Y_n -\\theta) -\\mathcal{Z}-> N(0, \\sigma^2)=> \\sqrt{n}[g(Y_n)- g(\\theta)-\\mathcal{Z}-> N(0, \\sigma_g^2)]$\n",
        "\n",
        "- con $\\sigma_g^2= [g`(\\theta)]^2\\sigma^2$\n",
        "\n",
        "Esempio: contiua:\n",
        "\n",
        "consideriamo ora $\\tau(\\theta)= \\theta(1-\\theta)$ e lo stimatore $T_n = \\bar{X}(1-\\bar{X})$ - E asintoticamente efficiente?\n",
        "\n",
        "Poinche: $g(\\theta)= \\theta(1-\\theta)= \\theta-\\theta^2$ e $g`(\\theta)= 1-2\\theta$ che e\\ $\\ne 0$ intanto che $\\theta \\ne 1/2$ si ha\n",
        "\n",
        "$\\sqrt{n}(\\bar{X})(1-\\bar{X})- \\theta(1-\\theta)-\\mathcal{Z}-> N(0, \\sigma_g^2(\\theta))$\n",
        "\n",
        "con $\\sigma_g^2(\\theta= (1-2\\theta)^2/theta(1-\\theta))==\\frac{\\tau`(\\theta)^2}{I(\\theta)}$\n",
        "\n",
        "e quindi lo stimatore e' asintoticamente efficiente e la sua varianza asintotica e quella sopra.\n",
        "\n",
        "Osservazioni:\n",
        "1. la varianza asintotica viene ragiunta , appunto asintoticamntte. Pertanto non e' detto che rappresenti una valutazone attendibile quando *n* e; finito: potrebbe cio, essere una sottostima della reale varianza.\n",
        "Nell esempio, se $\\theta$ e icino a 1/2 la varinaze e prativaente nulla, il che e' piutosto difficile  e meno che n non sia molto molto alto.\n",
        "\n",
        "2. l'esempio mostra che nonstante talvolta si possa stabilire che uno stimatore e' asintoticamente attuale non e' possibile dare una valutazione approssimativa della sua varianza in tutti casi. nell'esempio non ha si puo dira se $\\theta=1/2$ ma anche n generale poiche la varianza dipende da $\\theta$ e queesto non e' noto.\n",
        "\n",
        "3. nell esempio abbiamo trovato lo stimatore asintoticamente efficiente servendosi dell'intuito ma dobbiamo ricordare che $\\bar{X}$ e' anche lo stimatore di massima verosimiglianza nel modello bernouliano vale infatti questa teorema\n",
        "\n",
        "Teorema: Se il modello $f(x|\\theta)$ rispetta alcune condizioni di regolarita e $\\tau(\\theta)$ e' una funzione continua di $\\theta$, allora indicato con $\\hat{\\theta}$ lostimatrore di massima verosimiglianza di $\\theta$\n",
        "\n",
        "$\\tau(\\theta)$ e consitente, asintoticamente Normale , asintoticamnte efficiente per $\\tau(\\theta)$\n",
        "\n",
        "NB:\n",
        "- le condizioni di regolarita del modello sono molto spesso verificate, tuttavia sono esclisi i modelli il cui supporto dipende da $\\theta$\n",
        "\n",
        "- delle tre proprieta dello stimatore di MV l'efficienza asintotica e' quella piu rilevante poiche la rachiude tutte:\n",
        "  - Effciienza asintotica => Normalita asintotica + consistenza (e' facile mostrare che , se $\\T_n$ e asintoticamente efficeinte, $[T_n - \\tau(\\theta)]-\\mathcal{Z}-> 0$ e la convergenza in legge ad una costante equivale alla convergenza in probabilita)\n",
        "\n"
      ],
      "metadata": {
        "id": "yBcfJPZVhqFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Come precisato usare la varianza asintoticha per approssimare la varianza reale di uno stimatore che si sa essere asintoticamente efficiente (cme pr lo stimatore di MV) non e' sempre agevole- Nella formula:\n",
        "\n",
        "$Var(T_n)  \\approx \\frac{[\\tau`(\\theta)]^2}{n.E_{\\theta}[\\frac{\\partial}{\\partial \\theta} log(f(x|\\theta))^2]} = \\frac{[\\tau`(\\theta)]^2}{n.I(\\theta)}$\n",
        "\n",
        "Vi e' infatti la dipendenza da $\\theta$ e la necessita di calcolare l'esperessione dell'informazione di FIsher, cioe di un valore attesso non sempre semplice.\n",
        "\n",
        "Ci sono due modi di ovviane a queesti problemi:\n",
        "1. Sostituire $\\theta$ con lo stimatore di MV $\\hat{\\theta}$\n",
        "2. approsimare, il valore attesso al denominatore\n",
        "\n",
        "Se si usa solo la prima soluzione si ottiene\n",
        "\n",
        "$Var{T_n} \\approx \\frac{[\\tau`(\\theta)^2]_{\\theta=\\hat{\\theta}}}{n.I(\\hat{\\theta})}$\n",
        "\n",
        "dove $I(\\hat{\\theta})$ e detta spesso informazione di Fisher plug-in e richiede oviamente di conoscere l'espressione del valore attesso in funzione di $\\theta$\n",
        "\n",
        "Se si usa anche la seconda soluzione si puo considerare che in base alla legge dei grandi numeri un valore attesso si puo approsimare con una media campionari:\n",
        "\n",
        "$I(\\theta)= E_{\\\\theta}[\\frac{\\partial}{\\partial \\theta} log(f(x|\\theta))^2]= E_{\\theta}[-\\frac{\\partial^2}{\\partial \\theta^2} log(f(x|\\theta))] $ - come gia sappiamo\n",
        "\n",
        "- $ \\simeq -1/n \\sum_{i=1}^n \\frac{\\partial^2}{\\partial\\theta^2} log(f(x_i|\\theta))= \\hat{I}(\\theta)$\n",
        "\n",
        "Sostituendo ora a $\\theta$ lo stimatore di MV:\n",
        "\n",
        "$\\hat{I}(\\hat{\\theta})= -1/n \\sum_{i=1}^n \\frac{\\partial^2}{\\partial \\theta^2} log(f(x_i|\\theta))|_{\\theta=\\hat{\\theta}}$\n",
        "\n",
        "Pertanto si ha:\n",
        "$I_n(\\theta)= n.I(\\theta) \\simeq n.\\hat{I}(\\hat{\\theta})= -\\sum_{i=1}^n \\frac{\\partial^2}{\\partial \\theta^2} log(f(x_i|\\theta))|_{\\theta=\\hat{\\theta}}$\n",
        "\n",
        "\n",
        "Questa quantita e detta spesso Informazione di Fisher (de; Campione) Osservata. Da essa si ottiene la sequente approsimazione della varianza dello stimatore $T_n$\n",
        "\n",
        "$\\hat{Var}(T_n) = \\frac{[\\tau`(\\theta)^2|_{\\theta=\\hat{\\theta}}]}{n.\\hat{I}(\\hat{\\theta})}= ....= \\frac{[\\tau`(\\theta)^2|_{\\theta=\\hat{\\theta}}]}{-\\sum_{i=1}^n \\frac{\\partial^2}{\\partial \\theta^2} log(f(x_i|\\theta))|_{\\theta=\\hat{\\theta}}}$\n",
        "\n",
        "Esempio:\n",
        "\n",
        "Consideriamo un esempio elementare:\n",
        "\n",
        "$X_1...X_n$ iid $\\sim Poisson(\\theta)$ e $\\tau(\\theta)= \\theta$\n",
        "\n",
        "Per questo problema sappiamo che $\\hat{\\theta}= \\bar{X}$ cioe lo stimatore di MV che e' asintoticamente efficiente e' la media campionaria\n",
        "\n",
        "Il fatto che lo stimatore sia cosi semplice , ci permette naturalmente di calcolare in modo semplice la sua varianza: $Var_{\\theta}(\\bar{X})= \\theta/n$\n",
        "\n",
        "RImane tuttavia il problema dell'impossibilita di calcolare l'espresione sopre, poiche $\\theta$ non e' noto. Si po dunque pansare di sostiture $\\theta$ con $\\hat{\\theta}$ e colcolare una varianza plug-in\n",
        "\n",
        "$Var_{\\hat{\\theta}}(\\bar{X})= \\bar{X}/n$\n",
        "\n",
        "In questo esempio , allo stesso risultato si perviene se si applicano le technich di approsimazione della varianza viste sopra:\n",
        "1. se si determina l'inoformazione di Fisher e ci si limita a sostituire $\\theta$ con $\\hat{\\theta}$ si ottiene\n",
        "- $\\tau`(\\theta)=1$\n",
        "- $\\frac{\\partial^2}{\\partial \\theta^2} log(f(X|\\theta))= \\frac{\\partial^2}{\\partial \\theta}[\\theta.log(X)- \\theta - X!]= \\frac{\\partial}{\\partial \\theta}[\\frac{X}{\\theta} - 1] = -\\frac{X}{\\theta^2}$\n",
        "\n",
        "- $E[-\\frac{\\partial}{\\partial \\theta^2} log(f(X|\\theta))]= E[\\frac{X}{\\theta^2}]= \\frac{1}{\\theta^2}\\theta= \\frac{1}{\\theta} => \\hat{Var}(\\bar{X})= \\frac{1}{n.\\frac{1}{\\theta}}|_{\\theta=\\hat{\\theta}}= \\frac{\\bar{X}}{n}$\n",
        "\n",
        "\n",
        "2. Se si approssima anche l'informazione di Fisher, siottiene:\n",
        "\n",
        "- $\\frac{\\partial^2}{\\partial \\theta^2} log(f(X_i|\\theta))= -\\frac{X_i}{\\theta^2}$\n",
        "\n",
        "- $-\\frac{1}{n} \\sum_{i=1}^n log(f(X_i|\\theta)) = \\frac{1}{\\theta} \\sum_{i=1}^n X_i = \\frac{\\bar{X}}{\\theta^2}$\n",
        "\n",
        "- $n.\\hat{I}(\\theta) = \\frac{n.\\bar{X}}{\\theta^2}$\n",
        "\n",
        "- $n.\\hat{I}(\\hat{\\theta}) = \\frac{n.\\bar{X}}{\\bar{X^2}}= \\frac{n}{\\bar{X}}$\n",
        "\n",
        "=> $\\hat{Var}(\\bar{X}) = \\frac{1}{\\frac{n}{\\bar{X}}}= \\frac{\\bar{X}}{n}$\n",
        "\n"
      ],
      "metadata": {
        "id": "6WW8Q46ChqHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Approssimazione delle distribuzioni Campionarie Meiante simulazioni:\n",
        "\n",
        "Abbiamo visto che il ricorso alla teoria asintotica puo servire per approssimare la varianza di uno stimatore.\n",
        "\n",
        "Un metoo di approssimazione alternativo, che segua una logica completamnte diversa e' quelo basato sulle simulazion tramite il metodo Monte-Carlo. Abbiamo visto , infatti che e' possibile simulare il comportamento di una variabile aleatoria generando un numero elevato di valori derivanti dalla sua distribuzione . Poiche il campione e' una sequenza di variabili aleatoria, possiamo pensare di applicare il metodo Monte Carlo a tutti gli elementi del campione o a una loro funzione, cioe una statistica o uno stimatore.\n",
        "\n",
        "I risultati della simulazione dipendono, come comprensibile delle informaziooni di partenza. In alcvuni casi si puo parire da un modello statistico completamente noto. (anche per il valore dei parametri). Talvolta, invece, i parametri del modello non sono noti e non e' noto del tutto il modello statistico.\n",
        "\n",
        "va precisato inoltre che l'obbiettivo delle simulazion puo essere al varoianza dello stimatore , ma anche un'altra sua caratterstica?(o addotiva l'intera distribuzione campionaria)\n",
        "\n",
        "Distinguiamo diversi casi:\n",
        "\n",
        "1. Il moello statistico e' completamente noto.\n",
        "\n",
        "SI suppone di considerare un campione $X_1..X_n$ iid da un modello $f(x|\\theta)$\n",
        "completamente specificato (anche per $\\theta$) e una statistica: $T=T(X_1...X_n)$ la cui distibuzione campionaria , tuttavia e' difificile  da determinare. Pertanto occorre ricorrere a simulazioni:\n",
        "- fissato n , si generano M sequence IID dal modello $f(x|\\theta)$\n",
        "$$x_{1j}^*, x_{2j}^*... x_{nj}^*$$ i=1..n\n",
        "- par ogni sequnza si calcola il valore osservato di T: $t_i^*= T(t_{1i}^*, t_{2i}^*... t_{ni}^*)$ - i=1...M\n",
        "\n",
        "- si sintetizzano gli M valori ottenuti:\n",
        "$$\\bar{t}^*= \\frac{1}{M} \\sum_{i=1}^n t_i^*$$\n",
        "\n",
        "$$s_T^*= \\frac{1}{M-1} \\sum_{i=1}^M (t_i^* - \\bar{t}^*)^2$$\n",
        "\n",
        "la prima quantita e' un approsimazione di $E[T]$, la seconda di $Var{T}$\n",
        "\n",
        "NB: l'intera distribuzione di T potrebbe approssimata mediante l'instogramma degli M valori o mediante frequenza di specifici intervalli\n",
        "\n",
        "2. Il modello statistico e' noto, ma non e' noto il parametro (o i paramtri) che lo caratterizzano\n",
        "\n",
        "In questo cao, per poter generare osservazioni di $f(x|\\theta)$ e' ovviamente necessareio avere qualche informazione su $\\theta$.\n",
        "Spesso si assume di avere perlomeno una singola realizzazione campionaria , che verra utilizzata per ottenere (simulare) altre: si parla pertanto di metodi di RICAMPIONAMENTO . Nel caso specifico il metodo che consideramo viene detto BOOTSTRAP PARAMETRICO.\n",
        "\n",
        "- si stima $\\theta$ mediante la realizzazione compionaria osservata-> $\\hat{\\theta}$ (spesso si usa la stima di massima verosimiglianza)\n",
        "\n",
        "- fisato n, si generano M sequenze IID da $f(x|\\hat{\\theta})$\n",
        "\n",
        "$f(x|\\theta)$\n",
        "$$x_{1j}^*, x_{2j}^*... x_{nj}^*$$ i=1..M\n",
        "\n",
        "- si riportano i passi visti precedentemente\n",
        "\n",
        "3. Neanche il modello statistico e' noto:\n",
        "\n",
        " Chiaramente , anche in queesto caso dobbiamo perlomeno disporre di una realizzazione campionaria. Tuttavia questa non puo servire a stimare il modello statistico, perche questo non esiste. SI sa, tuttavia, che ciasuno dei dati ottenuti proviene dalla popolazione e potrebbe ripensantrsi se si generano altri dati dalla popolazione.\n",
        "\n",
        " SI decide , quindi di estrarre, casualmente e con reimissione, sequenza di n dati da $x_1,x_2..x_n$\n",
        "\n",
        "Cioe di effettuare un ricampionamento vero e proprio. SI parla di Bootstrap NON parametrioco.\n",
        "\n",
        "- si generano M sequenza:\n",
        "$f(x|\\theta)$\n",
        "$$x_{1j}^*, x_{2j}^*... x_{nj}^*$$ i=1..M\n",
        "estraentdo ogni volta n dati con reimissione da $x_1..x_n$\n",
        "\n",
        "- per ogni sequenza si cvalcola il valore osservato di T:\n",
        "$$t_i^* = T(x_{1i}^*, x_{2i}^*,..., x_{ni}^* ) $$ - i=1...M\n",
        "\n",
        "- si ripetono i passi precedenti\n",
        "\n",
        "Esempio: consideriamo n=4 e la seguente realizzazione campionaria: 11, 6, 23, 8\n",
        "\n",
        "inoltre consideriamo come stimatore la media campionaria: $\\bar{X}= \\frac{1}{4}(x_1+x_2+x_3+x_4)$\n",
        "\n",
        "Notiamo che la sue proprieta non sono scontate, poiche non abbiamo assunto niente riguardo alla popolazione.\n",
        "\n",
        "alcune delle sequenza ottenute dal bootstrap sono:\n",
        "- 6.11.11.8 => $t_1^*= 9$\n",
        "- 8,23,6,6 => $t_2^*= 10.75$\n",
        "- 11,23,8,6 => $t_3^*= 12$\n",
        "...\n",
        "\n",
        "qunte son in totale le sequenza ottenibili?\n",
        "\n",
        "Sono $4^4= 256$- Dunque in questo caso M=256\n",
        "\n",
        "L'esempio ci dice uno cosa molto importante. In generale, perche l'approssimazione ottnuta con le simulazioni si abuona, M deve essere un numero elevato. Nel caso del bootstrap non parametrico, tuttavia, l'ideale sarebbe oavere $M=n^n$. All aumentare di n , tale numero diventa velocemente poibitivo(per n=15 si ha $15^{15} \\sim (4.38).10^{17}$) e dunque bisogna scegliere un numero inferiore ma sufficiente elevato (tale numero e' il \"numero di campioni bootstrap\")\n",
        "\n",
        "Esempio:\n",
        "\n",
        "Per un campione $X_1...X_15$ con n=15 si considera la mediana campionaria: $T=X_{(8)}$\n",
        "\n",
        "data la realizzazione campionaria:\n",
        "- $-2,-0.2,-5.2,-3.5,-3.9$\n",
        "- $-0.6, -4.3, -1.7, -9.5, + 16$\n",
        "- $-2.9, +0.9, -1, -2 , +3$\n",
        "\n",
        "e stato implementao il metodo bootstrap e la varianza approssimata ottenuta col metodo e' stata:\n",
        "\n",
        "- $\\hat{Var}(T)= 0.770866$ - con M=  1000\n",
        "- $\\hat{Var}(T)= 0.718612$ - con M=10 000\n",
        "- $\\hat{Var}(T)= 0.704928$ - con M=100 000\n",
        "\n",
        "si nota come il valore tenda a stabilizzarsi - DUnque quello ottenuto per M=100 000 puo essere considerato una approssimazione attndibile.\n",
        "\n"
      ],
      "metadata": {
        "id": "3kMoidUohqN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intervalli di COnfidenza Asintotici:\n",
        "\n",
        "Poiche come sappiamo un intervallo di confidenza puo essere ottenuto invertendo la regione di accetazione di un test, alcuni intervallo di confidenza assintotici si possono ricavare dai metodi asintotici visti inprecedenza per i test. I piu utilizzati sono certamente quelli basati sul metodo di Wald, anche se non e' scontato che siano i migliori in temini di probabilita di copertura e di lungezza.\n",
        "\n",
        "Esempio:\n",
        "\n",
        "$X_1...X_n$ IID $\\sim Bernoulli(\\theta)--- 0< \\theta< 1$\n",
        "\n",
        "1. Utilizzando la regione di accettazione del test per $H_0: \\theta=\\theta_0$ contro $H_1: \\theta\\ne \\theta_0$ basato sulla distribuzione asintotica del rapporto di verosimiglianza, si dovra invertire rispetto a $\\theta_0$ l\\espressione\n",
        "\n",
        "$$-2.log[\\frac{\\theta_0^{\\sum x_i} (1-\\theta_0)^{n-\\sum x_i}}{\\bar{x}^{\\sum x_i} (1-\\bar{x})^{n-\\sum x_i}}] =< \\chi_{1;\\alpha}^2$$\n",
        "\n",
        "2. Utilizzando il corripsondente test di Wald basato sul fatto che\n",
        "\n",
        "$$\\frac{\\bar{X}-\\theta}{\\sqrt{\\frac{\\bar{X}(1-\\bar{X})}{n}}} -\\mathcal{Z}-> N(0,1)$$\n",
        "\n",
        "Si dovre invertire , rispetto a $\\theta_0$\n",
        "\n",
        "$$-Z_{\\alpha/2} < \\frac{\\bar{x} - \\theta_0}{ \\sqrt{\\frac{\\bar{x}(1-\\bar{x})}{n}}}  < Z_{\\alpha /2}$$\n",
        "\n",
        "queso e' lintervallo asintotico piu utilizzato:\n",
        "\n",
        "$\\bar{x} -+ z_{\\alpha/2} \\sqrt{\\frac{\\bar{x}(1-\\bar{x})}{n}}$\n",
        "\n",
        "\n",
        "3. Utilizzando lo score- test, si dovra invertire rispetto a $\\theta_0$\n",
        "\n",
        "\n",
        "$$-Z_{\\alpha/2} < \\frac{\\bar{x} - \\theta_0}{ \\sqrt{\\frac{\\theta_0(1-\\theta_0)}{n}}}  < Z_{\\alpha /2}$$\n",
        "\n",
        "NB: l'inversione non e' semplice. SUl casella-Berrger e'riportato il risultao e anche alcune simulazione per confronttre i tre intervalli\n",
        "\n"
      ],
      "metadata": {
        "id": "hyK-fvtThqSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DE-SvHkOhqUY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zYZzAfkvhqWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mFH-BjzvhqYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dbOvALcAhqa1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jhg4tEQlhqdG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "a3XqqPguhqfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rZz7Vygwhqlv"
      }
    }
  ]
}