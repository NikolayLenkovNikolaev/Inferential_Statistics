{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfIbJi3GSw01YdT9xDWlsA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikolayLenkovNikolaev/Inferential_Statistics/blob/main/L1ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stMg4SXnTqyh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment:\n",
        "- consider the outcome of an experiment such as:\n",
        "1. a collection of measurements from a sampled population\n",
        "- measurements from a laboratory experiment\n",
        "- the result of a clinical trial\n",
        "- the result from a simulated experiment\n",
        "- values from hosptal records sampled retrospectively\n",
        "\n",
        "### Set notation:\n",
        "- saple space $Ω$ is the collection of possible outcomes of an experriment:\n",
        "  - ex: $\\Omega = [1,2.3...6]$\n",
        "- event: say E is a subset of $\\omega$\n",
        "  - ex: E= 2,4,6 roll is event\n",
        "- an elementary or simple event is a particular result of an experiment:\n",
        "- ex: die roll is a four , w=4\n",
        "- $\\emptyset$ is called the null event or the empty set\n",
        "\n",
        "Interpretation of set operations:\n",
        "- Normal set operations have particular interpretation in this setting:\n",
        "1. $w \\in E$ implies the E occurs when w occurs\n",
        "2. $w ∉ E$ implies that E does not occur when w occurs\n",
        "3. $E  \\subset F$ implies that the occurence of E implies the occurence of F\n",
        "4. $E \\cup F$ implies the event that both E and F occur\n",
        "5. $E \\cap F$ implies the event that at least one of E or F occur\n",
        "6. $E \\cup F = ∅$ means that E and F are mutually exclusive, or cannot both occur\n",
        "7. $E^C$ or $\\bar{E}$ is the event that E does not occur\n",
        "\n",
        "\n",
        "Set theory facts:\"\n",
        "1. DeMorgan's laws:\n",
        "- $(A \\cap B)^C = A^C \\cup B^C$\n",
        "- $(A \\cup B)^C = A^C \\cap B^C$\n",
        "\n",
        "Example: if an aligator or a turtle you are not $(A \\cup B)^C$ then you are not an aligator and you are also not aturtle $(A \\cap B)^C$\n",
        "- if your car is not both hybrid and disel $(A \\cap B)^C$ then your car is either not hybrid or not disel $(A \\cup B)^C$\n",
        "\n",
        "- $(A^C)^C = A$\n",
        "- $(A \\cup B) \\cap C = (A \\cap C) \\cup (B \\cap C)$\n",
        "\n",
        "\n",
        "Useful strategy used in much of science:\n",
        "\n",
        "For a given experiment:\n",
        "- attribute all that is known or theorized to a systematic model (mathematical function)\n",
        "- attribute everything else to random , even if the process under study is known not the be \"random\" in any sense of the word.\n",
        "- evaluate the sensitivity of your conclusion to the assumptions of your model\n",
        "\n",
        "\n",
        "Important questions:\n",
        "1. what is being modeled as random?\n",
        "2. Where does this attributed arandomness arise from?\n",
        "3. where did systematic model components arise from?\n",
        "4. How didi observational units come to be in the study and is there importance to the missing data points?\n",
        "5. Do the results generalize beyond the study in question?\n",
        "6. Were important variables unacconted for in the model?\n",
        "7. How drastically would inferences chjange depending on the answers to the previous questions?\n",
        "\n"
      ],
      "metadata": {
        "id": "3EODCCL-UAOJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PROBABILITY and Variables:\n",
        "\n",
        "Prob.measures: 1a prob measure, P is a realvalued function from the collection of possible events so that the following hold\n",
        "1. For anevent $E \\subset \\Omega , 0=< P(E) =< 1$\n",
        "2. $P(\\Omega) = 1$\n",
        "3. if $E_1$ and $E_2$ are mutually esclusive events $P(E_1 \\cup E_2) = P(E_1) + P(E_2)$\n",
        "\n",
        "\n",
        "ADDITIVITY:\n",
        "Part 3 of the definition implies **finite additivity**:\n",
        "$$P(U_{i=1}^n A_i) = \\sum_{i=1}^n P(A_i)$$\n",
        "\n",
        "where $A_i$ ae mutually exclusive.\n",
        "\n",
        "This is usually extended to **countable additivity**\n",
        "$$P(U_{i=1}^n A_i) = \\sum_{i=1}^{\\infty} P(A_i)$$\n",
        "\n",
        "\n",
        "Note:\n",
        "- P is defined on $\\mathcal{F}$ a collections of subset of $\\omega$\n",
        "Ex: $\\Omega = [1,2,3]$ =  $\\mathcal{F} = { ∅, {1}, {2}, {3}, {1,2} ... {1,2,3}}$\n",
        "\n",
        "- when $\\omega$ is a continuous set, the definition gets much trickier. In this case we assume that $\\mathcal{F}$ is sufficientrly rich so that any set we're intereseted in will be in it.\n",
        "\n",
        "CONSEQUENCES:\n",
        "You should be able to prove all of the following:\n",
        "- $P(∅) = 0$\n",
        "- $P(E) = 1 - P(E^C)$\n",
        "- $P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$\n",
        "- if $A \\subset B $ then $P(A) =< P(B)$\n",
        "- $P(A \\cup B) = 1 - P(A^C \\cap B^C)$\n",
        "- $P(A \\cap B^C) = P(A) - P(A \\cap B)$\n",
        "- $P(U_{i=1}^n E_i) =< \\sum_{i=1}^n P(E_i)$\n",
        "- $P(U_{i=1}^n E_i) >= max P(E_i)$\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NdbNhclTUAQZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RANDOM VARIABLES:\n",
        "- a random variables is anumerical outcome of an experiment.\n",
        "- the ran.var that we study will come in two variates, discrete or continuous\n",
        "- disrete r.v. are random variables that take on only a countable number of possibilities $P(X=k)$\n",
        "- Continuous r.v. can take any value on the real line or some subset of the real line $P(X \\in A)$\n",
        "\n"
      ],
      "metadata": {
        "id": "85eqf87dUAS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PMFs:\n",
        "A prob mass function at a value correspnds to the probability that a random variables takes that value. To be a valid pmf a function, p , must satisfy\n",
        "1. $p(x) >= 0$  for all x\n",
        "2. $\\sum_x p(x)= 1$\n",
        "\n",
        "The sum is taken over all of the possible values for x.\n",
        "\n",
        "\n",
        "### PDFs\n",
        "A prob. density function pdf is a function associated with a continuous random variable\n",
        "\n",
        "Areas under pdfs correspond to probability for that random variable\n",
        "\n",
        "To be a valid pdf, a function f must satisfy\n",
        "1. $f(x) >= 0$  for all x\n",
        "2. $\\int_{-\\infty}^{\\infty} f(x) dx = 1$\n",
        "\n",
        "\n",
        "Example:\n",
        "Assume that the time in years from diagnosis until of persons with a specific kind of cancer follows a density like:\n",
        "\n",
        "$$f(x) $$\n",
        "$\\frac{e^{-x/5}}{5} for x >0$\n",
        "\n",
        "$0$ otherwise\n",
        "\n",
        "More compactly writen: $f(x)= \\frac{1}{5} e^{-x5}$ for x >0\n",
        "\n",
        "is this a valid density?\n",
        "1. e raised to any power is always positive\n",
        "2. $\\int_0^{\\infty} f(x) dx = \\int_0^{\\infty} e^{-x/5} / 5 dx = -e^{-x/5} |_0^{\\infty} = 1$\n",
        "\n",
        "What is the probability that a random selected aperson from this distibution survives more than 6 years?\n",
        "\n",
        "$$P(X >= 6) \\int_6^{\\infty} \\frac{e^{-t/5}}{5} dt = -e^{-t/5}|_6^{\\infty}= e^{-6/5} \\sim 0.301$$\n",
        "\n",
        "```\n",
        "pexp(6, 1/5, lower.tail= False)\n",
        "```\n",
        "\n",
        "Survival time ???!!!\n",
        "\n"
      ],
      "metadata": {
        "id": "yew4ykt_UAVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CDFs, Survival Functins and Quantiles\n",
        "\n",
        "CDF and survival function\n",
        "\n",
        "- the **cumulative distributio function CDF** of a randm var X is defined as the func: $$F(x) = P(X =< x)$$\n",
        "\n",
        "- this definition applies regardless of whether X is discrete or continuous.\n",
        "\n",
        "- the Survival function of a random variables X is defined as $S(x)= P(X>x)$\n",
        "\n",
        "- notice that $S(x)= 1-F(x)$\n",
        "\n",
        "- for continuous ran.var the PDF is the derivative of the CDF\n",
        "\n",
        "EXaplie:What are the survival functio nand CDF from the exponential density considered before?\n",
        "\n",
        "$$S(x)= \\int_x^{\\infty} \\frac{e^{-t/5}}{5} dt = -e^{-t/5} |_x^{\\infty} = e^{-x/5}$$\n",
        "\n",
        "Hence we kmow that:\n",
        "$F(x)= 1-S(x) = 1-e^{-x/5}$\n",
        "\n",
        "Notice that we can recover the PDF by: $$f(x)= F`(x)= \\frac{d}{dx} (1-e^{-x/5})= e^{-x/5} / 5$$\n"
      ],
      "metadata": {
        "id": "jQCFrMnwUAXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantiles:\n",
        "- the $a^{th}$ qiantile of a distribution with distribution function F is the point $x_a$ so tht $F(x_a) = \\alpha$\n",
        "\n",
        "- a perecentile is simply a quantile with $\\alpha$ expressed a s percent\n",
        "- the mdian is the $5-^{th}$ percentile\n",
        "\n",
        "\n",
        "Example: what is the 25th percentile of the exponential survival dstribution considered before?\n",
        "- we want to solve (for x)\n",
        "$$0.25 = F(x) => 1- e^{-x/5}$$\n",
        "\n",
        "$x = -log{0.75} . 5 \\sim 1.44$\n",
        "\n",
        "- therefore 25% ot the subjects from this population live less than 1.44 years\n",
        "\n",
        "```\n",
        "R can approximate exponential quantiles for you:\n",
        "qexp(0.25, 1/5)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "dA6M3EeLUAZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prob models:\n",
        "- you might be wondering at this poit \"I have heard of median before, it didn't require integration, Where is the data?\"\n",
        "- we are referring to are population quantities. Therefore, the median being discussed is the population median.\n",
        "- a probability model connects the data to the population to the population using assumptions.\n",
        "- therefore the median we are discusseing is the estimand, the sample median will be the estimator.\n",
        "\n"
      ],
      "metadata": {
        "id": "w4yzmwe7UAb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Expected Values:\n",
        "- the e.v or mean of a random variables is the centerof its distribution\n",
        "- for discrete random variables X with PMF p(x)., it is difined as follows $E[X]= \\sum_x x.p(x)$ where the sum is taken over the possible values of x.\n",
        "- E[X] represent the center of mass of a colection of locations and weights {x, p(x)}\n",
        "\n",
        "Ex: suppose a coin is flipped and X is declareed 0 or 1 coresponding to a head or a tail , respectively\n",
        "- what is the expected value of X?\n",
        "- $E[X]= 0.5*0 + 0.5*1= 0.5$\n",
        "\n",
        "Note if thought about geometrically , this answear is obvious, if two equal weights are spaced at 0 and 1, the center of mass will be 0.5\n",
        "\n",
        "Suppose that a die is roled and X is the number face up\n",
        "\n",
        "what is the expected value of X?\n",
        "\n",
        "$E[X]= 1*1/6 + 2*1/6 + ... 6*1/6= 0.35$\n",
        "\n",
        "again the geometric argument makes this answer obvous without calculation\n",
        "\n",
        "\n",
        "CONTINUOUS RANDOM VARIABLES:\n",
        "- FOR A CONTINUOUS RANDOM VARIABLE, X with density , f, the expected value is defined as follows $E[X]= \\int_{-\\infty}^{\\infty} tf(t) dt$\n",
        "- this definition borrows from the definition of center of mass for a continuous body\n",
        "\n",
        "\n",
        "\n",
        "EX: consider a density where f(x)=1 for x between xzero and one\n",
        "- is this valid density?\n",
        "- suppose that X follows this density , what is its expected valuie?\n",
        "\n",
        "$E[X]= \\int_0^1 xdx = \\frac{x^2}{2} |_0^1 = 1/2$\n",
        "\n"
      ],
      "metadata": {
        "id": "joIvh7WJUAeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rules about expected values\n",
        "\n",
        "- the exxpected value is a linear operator\n",
        "- if a and b are not random and X and Y are two random variables then\n",
        "- $E[aX + b]= a.E[X] + b$\n",
        "- $E[X+Y] = E[X] + E[Y]$\n",
        "\n",
        "- in general if g is a function that is not linear $E[g(X)] \\ne g(E[X])$\n",
        "\n",
        "for ex: in general $E[X^2] \\ne E[X^2]$\n",
        "\n",
        "\n",
        "Example:\n",
        "- you flip a coin, X and simulate a uniform ran.number Y, what is the expected value of their sum?\n",
        "\n",
        "$E[X+Y] = E[X] + E[Y] = 0.5+0.5=1$\n",
        "\n",
        "Another example ,you roll a die twice. What is the expected value of the average?\n",
        "- let $X_1$ and $X_2$ be the results of the two rolls.\n",
        "$$E[(X_1+X_2)/2] = 1/2 (E[X_1] + E[X_2]) = 1/2(3.5 + 3.5)= 3.5$$\n",
        "\n",
        "Example: Let $X_i$ for i=1...n be a collection of random vari,, each from a distribution with mean $\\mu$\n",
        "- calulate the expected value of the sample average f the $X_i$\n",
        "\n",
        "$$E[1/n \\sum_{i=1}^n X_i] = 1/n E[\\sum_{i=1}^n X_i] = 1/n \\sum_{i=1}^n E[X_i]= 1/n \\sum_{i=1}^n \\mu=\\mu$$\n",
        "\n",
        "Remark:\n",
        "- therefore , the expected value of the sample mean is the populationmean that it's tryinf to stimate\n",
        "\n",
        "- when the expected value of an estimator is what its trying to estimate, we say that the estimator un **unbiased**\n",
        "\n"
      ],
      "metadata": {
        "id": "zSzZCkHCUAgL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Varinace ana Chybyshev Inequality\n",
        "\n",
        "The variance of a random variable is ameasure of spread\n",
        "0 if X is a random varible with mean $\\mu$, the variance of X is defined as $Var[X]= E[(X-\\mu)^2]$\n",
        "\n",
        "the expected (squared ) distance from the mean\n",
        "- densities with a higher variance are more spread out than densities with a lower variance\n",
        "\n",
        "\n",
        "COnvenitent computational from $Var[X]= E[X^2]- E[X]^2$\n",
        "- if a sis constant then $Var(aX)= a^2Var(X)$\n",
        "- the suqare root of the variance is called the standard deviation\n",
        "- the s.d has same units as X\n",
        "\n",
        "\n",
        "Example:\n",
        "What is the sample variance from the result of a toss of adie?\n",
        "- E[X]=35\n",
        "- $E[X^2]= 1^2*1/6 + 2^2*1/6 +...+ 6^2*1/6=15.17$\n",
        "\n",
        "$$Var[X]= E[X^2] -E[X]^2\n",
        " \\sim 2.92$$\n",
        "\n",
        " What's the sample variance from the result of the toss of a coin with probability of heads (1) of p?\n",
        " - $E[X]= 0*(1-p) + 1*p=p$\n",
        " - $E[X^2] = E[X] = p$\n",
        "\n",
        " - $Var[X]= E[X^2]-E[X]^2= p-p^2= p(1=p)$\n",
        "\n",
        "\n",
        " Example:\n",
        " Suppose that a random variables is such that $0=< X =< 1$ and $E{X]=p$\n",
        " - Note $X^2 =< X$ so that $E[X^2] =< E[X]=p$\n",
        " - $Var[X] = E[X^2] -E[X]^2 =< E[X] - E[X]^2 = p(1-p)$\n",
        "\n",
        " Therefore the Bernoulli variance is the largest possible for random variables bounded between 0 and 1\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "RBPHBH53UAif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "INTER{RETOMG VARIANCE\n",
        "- chebyshev's inequality is useful for interpreting variance\n",
        "- this inqeuality stats that:\n",
        "$$P(|X-\\mu| >=k.\\sigma) =< \\frac{1}{k^2}$$\n",
        "\n",
        "For example, the prob tht a random variables lies beyond k s.d from its mean is less than $1/k^2$\n",
        "- $2\\sigma -> 25$%\n",
        "- $3.\\sigma -> 11$%\n",
        "- $4.\\sigma ->6$%\n",
        "\n",
        "Note this is only a bound, the actual prob might be quite a bit smaller\n",
        "\n",
        "Prof of Chebyshev's inequality:\n",
        "\n",
        "...\n",
        "\n"
      ],
      "metadata": {
        "id": "sF_64EKSUAkd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Vectors\n",
        "\n",
        "R.V are simply random variables collectioed into a vector\n",
        "  - ex: if X and Y are random variables (X,Y) is a r.v.\n",
        "\n",
        "- Joint density f(x,y) satisfies f>0 and $\\int \\int f(x,y) = dxdy=1$\n",
        "- for discrete random variables $\\sum \\sum f(x,y) = 1$\n",
        "- in thsi lecture we focus on independent random variables where $f(x,y)= f(x)g(y)$\n"
      ],
      "metadata": {
        "id": "5DI1Cbe9UAm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "INDEPENDENT EVENTS\n",
        "- Two events A and B are independent if\n",
        "$P(A \\cap B) = P(A). P(B)$\n",
        "\n",
        "Two andom variables , X and Y are independent if for two sets A and B\n",
        "\n",
        "$$P([A \\in A]) \\cap [Y \\in B] = P(X \\in A). P(Y \\in B)$$\n",
        "\n",
        "If A is independent of B then\n",
        "- $A^C$ is independent of B\n",
        "- A is independent of $B^C$\n",
        "- $A^C$ is independent of $B^C$\n",
        "\n",
        "Useful fact:\n",
        "- we will use the following fact extensively in this class: if a collection of random variables $X_1, X_2...X_n are independent, then their joint distribution is the product of their individual densities or mass functions.$\n",
        "\n",
        "That is, if $f_i$ is the density for random variable $X_i$ we have that:\n",
        "$$f(x_1...x_n)= \\prod_{i=1}^n f_i(x_i)$$\n",
        "\n",
        "\n",
        "IID RANDOM VAR\n",
        "- in the instance where $f+1=f_2 =...=f_n$ we say that the $X_i$ are iid for indepdent and identically distributed\n",
        "\n",
        "- iid random variables are the default model for andom sample\n",
        "- many of the important theories of statistics are founded on assuming that variables are iid\n",
        "\n",
        "Ex: suppose that we fliop a biased coin with success probability p n times, what is the join density of the collection of outcome?\n",
        "- these random variables are iid with densities $p^{x_i}(1=p^{1-x_i})$\n",
        "\n",
        "Therefore:\n",
        "$$f(x_1...x_n)= \\prod_{i=1}^n p^{x_i}(1-p)^{1-x_i} = p^{\\sum x_i} (1-p)^{n-\\sum x_i}$$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F4bxH_tQpy9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation:\n",
        "\n",
        "The covariance between two random variables X and Y is defined as:\n",
        "\n",
        "$Cov(X,Y)= E[(X-\\mu_x)(Y-\\mu_y)] = E[XY] - E[X]E[Y]$\n",
        "\n",
        "the following are useful facts about covariance\n",
        "- $Cov(X,Y)= Cov(Y,X)$\n",
        "- $Cov(X,Y)$ can be negative or positive\n",
        "- $|Cov(X,Y)| <= \\sqrt{Var(X)Var(Y)}$\n",
        "\n",
        "CORRELATION:\n",
        "The correlation between X and Y is\n",
        "\n",
        "$$Cor(X,Y) = Cov(X,Y) / \\sqrt{Var(X). Var(y)}$$\n",
        "\n",
        "- $-1 =< Coe(X,Y) =< 1$\n",
        "- $Cor(X,Y) = +- 1 $ if and only if X=a + bY for some constants a and b\n",
        "- Cor(X,Y) is unitless\n",
        "- X and Y are uncorrelated if Cov(X,Y)=0\n",
        "- X and Y are more sotitively correlated, the closer COr(X,Y) is to 1\n",
        "- X and Y are more negatively correlated, the closer COr(X,Y) is to -1"
      ],
      "metadata": {
        "id": "hvxLTioFpy_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some useful results\n",
        "\n",
        "Let $[X_i]_{i=1}^n$ be a collection of randaom variables\n",
        "\n",
        "- when the $[X_i]$ are uncorrelated\n",
        "\n",
        "$$Var[ \\sum_{i=1}^n a_iX_i + b] = \\sum_{i=1}^n a_i^2 Var(X_i)$$\n",
        "\n",
        "Otherwise:\n",
        "\n",
        "$Var(\\sum_{i=1}^n a_iX_i + b) = \\sum_{i=1}^n a_i^2. Var(X_i) + 2 \\sum_{i=1}^{n-1} \\sum_{j=1}^n a_i a_j Cov(X_i, X_j) $\n",
        "\n",
        "If the $X_i$ are iid with variance $\\sigma$ then $Var(\\bar{X})= \\sigma^2 / n$  and $E[S^2] = \\sigma^2$\n",
        "\n",
        "\n",
        "\n",
        "Results:\n",
        "- a commonly used subcase form these propertes is that if a collection of random variables {$X_i$} are uncorrelated, then the variance of the sum is the sm of the variances\n",
        "$$Var[\\sum_{i=1}^n X_i] = \\sum_{i=1}^n Var(X_i)$$\n",
        "\n",
        "- therefore, it is sums of variances that tend to be useful , not sums of standard deviations, that is, the standard deviation, ot the sum of bunch of independent random variables is the square root of the sum of the variance, not the um of the s.deviations\n",
        "\n"
      ],
      "metadata": {
        "id": "oWKaoTYspzCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variance Propertioes and Sample Variances\n",
        "\n",
        "The sample mean:\n",
        "\n",
        "Suppose $X_i$ are iid with variance $\\sigma^2$\n",
        "\n",
        "$$ Var[\\bar{X}] = Var(1/n \\sum_{i=1}^n X_i) = 1/n^2 Var(\\sum_{i=1}^n X_i) = 1/n^2 \\sum_{i=1}^n$ Var(X_i) = 1/n^2 * n\\sigma^2 = \\sigma^2 /n $$\n",
        "\n",
        "```\n",
        "# 1 000 rols\n",
        "barplot(table(sampe(1:6, 1000, replace=True)), col=\"lightblue\")\n",
        "\n",
        "# 1K average of 10 die rolls in R and plot the histogram\n",
        "\n",
        "n <- 10\n",
        "nosim <= 1000\n",
        "xbar<- apply(matrix(sample(1:6, n*nosim, replace=True), nosim), 1, mean)\n",
        "Barplot(table(xbar), col= \"lightblue\")\n",
        "var(xbar)\n",
        "```\n",
        "\n",
        "COmments:\n",
        "\n",
        "When $X_i$ are independent with a common variance $Var(\\bar{X}) = \\frac{\\sigma^2}{n}$\n",
        "- $\\sigma / \\sqrt{n}$ called the standard error of the sample mean\n",
        "- the st.error of the sample mean is the st.deviation of the distribution of the sample mean\n",
        "- $\\sigma$ is the st.dev of the distribution of asingle observation\n",
        "- easy way to remember , the sample mean has to be les veaible then a single observation, therefore its standard deviation is divided by a $\\sqrt{n}$\n",
        "\n"
      ],
      "metadata": {
        "id": "sylxaZiHpzE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAMPLE VARIANCE\n",
        "\n",
        "The sample var is defined as: $S^2 = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}$\n",
        "\n",
        "The sample variance is an estimator of $\\sigma^2$\n",
        "\n",
        "The numerator has a version that is quicker for calculation\n",
        "\n",
        "$\\sum_{i=1}^n (X_i - \\bar{X})^2 = \\sum_{i=1}^n X_i^2 - n.\\bar{X}^2$\n",
        "\n",
        "The sample variabce is (nearly) the mean of the squared deviations from the mean\n",
        "\n",
        "THE SAMPLE VARIANCE IS UNBIASED\n",
        "\n",
        "equation ....\n",
        "\n",
        "$E[\\sum_{i=1}^n (X_i - \\bar{X})^2] = \\sum_{i=1}^n E[X_i^2] - nE[\\bar{X}^2]$\n",
        "\n",
        "$\\sum_{i=1}^n (Var(X_i) +\\mu^2) - n(Var(\\bar{X}) +\\mu^2)$\n",
        "\n",
        "$\\sum_{i=1}^n (\\sigma^2 +\\mu^2) - n(\\sigma^2 / n + \\mu^2)$\n",
        "\n",
        "$ n.\\sigma^2 + n.\\mu^2 - \\sigma^2 - n\\mu^2 = (n-1)\\sigma^2$\n",
        "\n"
      ],
      "metadata": {
        "id": "G6Cee_IrpzHV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hoping to avoild some confusion:\n",
        "- suppose $X_i$ are iid with mean $\\mu$ and Variance $\\sigma^2$\n",
        "\n",
        "- $S^2$ estimates $\\sigma^2$\n",
        "\n",
        "- The calculation of $S^2$ involves dividing bt $n-1$\n",
        "- $\\frac{S}{\\sqrt{n}}$ estimates $\\frac{\\sigma}{\\sqrt{n}}$ the stnadard error of the mean\n",
        "- $\\frac{S}{\\sqrt{n}}$ is called the sample standard error of the mean\n",
        "\n",
        "Ex:\n",
        "\n",
        "in a study of 495 organo-lead worker, the followng summaries were obtained fot TBV in cm^3\n",
        "\n",
        "- mean = 1151,281\n",
        "- sum of squared observations = 662361978\n",
        "- sample sd = $\\sqrt{(662361978 - 495*1151.281^2)} = 112.6215$\n",
        "- estimated se of the mean = 112.6215 / \\sqrt{495} = 5.062\n",
        "\n"
      ],
      "metadata": {
        "id": "-KTm4mSZpzJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NikolayLenkovNikolaev/Inferential_Statistics.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP8d-VZBh3WP",
        "outputId": "a3802c83-e851-402b-8d81-757d5cbe6965"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Inferential_Statistics' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pat = 'https://github.com/NikolayLenkovNikolaev/Inferential_Statistics.git'\n",
        "!git clone https://{pat}@github.com/username/repo.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB_kQrcDiCzC",
        "outputId": "338d4914-5a7b-4480-8410-2bb9d70c8058"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'repo'...\n",
            "fatal: unable to access 'https://https://github.com/NikolayLenkovNikolaev/Inferential_Statistics.git@github.com/username/repo.git/': Could not resolve host: https\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pat = 'Token here'\n",
        "!git clone https://{pat}@github.com/username/repo.git"
      ],
      "metadata": {
        "id": "VTbgFStopzLy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nS87AVHIpzOb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cNSvdLKlpzQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CZjR1ZB7pzS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oOI11B9-pzVR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SChoVtuApzXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9J6LyiI7pzZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "35rwxzPOpzcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3roEc_QJpzga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WCpOGGJBpzjH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "80qm-ni0pyKE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}